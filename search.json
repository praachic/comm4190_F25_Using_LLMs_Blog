[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hi! I‚Äôm Praachi. I‚Äôm a junior at Penn studying Economics with minors in Data Science & Analytics, Consumer Psychology, and Cognitive Science! I love baking, exploring, and anything related to plants!"
  },
  {
    "objectID": "posts/017_Can ChatGPT Know When Not to Answer/index.html",
    "href": "posts/017_Can ChatGPT Know When Not to Answer/index.html",
    "title": "Does ChatGPT Know when NOT to Answer?",
    "section": "",
    "text": "Setup:\nAs far as I know, ChatGPT is often trained to provide the best possible answer for any prompt or situation. What happens if the situation at hand is best unanswered? Today I will be testing ChatGPT with a few different situations and seeing if and when Chat knows when to stay silent.\n\n\nExperiment:\nI will start by giving chat a variety of completely made up situations that I believe warrants a lack of a reply.\nWe start with a simple example: a spam call &gt;Hi chat. I just received a call from a number I don‚Äôt know. Apple has marked it as ‚ÄúSpam Likely.‚Äù What should I do?\nChatGPT Answered: &gt;What You Should Do &gt; 1. Don‚Äôt answer or engage with the call. Answering can confirm your number is active, which can lead to even more spam calls in the future. LifeLock Never give out personal info, passwords, account numbers, or anything else sensitive. &gt; 2. Let it go to voicemail or ignore it. If it‚Äôs important (like a doctor‚Äôs office), they‚Äôll leave a voicemail or try another way to contact you. &gt; 3. Block the number after the call. On iPhone: Open the Phone app ‚Üí Recents ‚Üí tap the ‚Äúi‚Äù next to the number ‚Üí Block this Caller. This prevents that specific number from calling you again.\nGood! It seems that in a basic ‚Äúanswer or don‚Äôt answer‚Äù situation, ChatGPT was able to pick the correct answer. This, however, is a very easy example as there are only two real answers. Let‚Äôs try a more nuanced example.\nIn a new temporary chat, I ask ChatGPT: &gt;Hi Chat. A girl from one of my classes has repeatedly been a bit mean to me and crossed my boundaries. I have tried to communicate but it doesn‚Äôt work. She alternates between treating my like a friend and being mean and I do not want to engage in that. She just texted me ‚Äúare you busy?‚Äù Truthfully I am not busy at all but I dont want to tell her that and I dont want to lie. what should I do?\nChatGPT replies: &gt;Here are a few honest, boundary-respecting options you can choose from, depending on how much distance you want: &gt; &gt;Option 1: Polite + neutral (low engagement) This keeps things calm without inviting conversation. ‚ÄúI‚Äôm not available right now.‚Äù ‚ÄúI can‚Äôt talk at the moment.‚Äù Both are true and don‚Äôt require explanation. &gt; &gt;Option 2: Gentle but clearer boundary If you want to subtly signal distance: ‚ÄúI‚Äôm taking some space today.‚Äù ‚ÄúI‚Äôm not up for chatting right now.‚Äù Still honest, still respectful. &gt; &gt;Option 3: No reply (also valid) You are allowed to not respond immediately or at all, especially given the pattern you described. Silence is a boundary, not rudeness.\nIt was provided as an option! I noticed that it was provided as the last option and was given a ‚Äúdisclaimer‚Äù of sorts that said ‚Äú(also valid).‚Äù The being said it was still provided as an option. Let‚Äôs see if we can get to a situation where ChatGPT reccomends a non-answer as the first choice.\nI ask: &gt;Hi chat. A girl I know starts gossiping about someone else I don‚Äôt really know. I don‚Äôt know them well enough to defend them, but I also don‚Äôt agree with what‚Äôs being said. She pauses after her comment and looks at me, clearly waiting for my reaction. I feel the pressure to agree, add something, or respond somehow despite not actually agreeing. I know that engaging would pull me into drama I don‚Äôt want to be part of. What should I do?\nSince ChatGPT‚Äôs response was relatively long, I will only put the first choice option here: &gt;1. Neutral + non-committal (often the easiest) &gt; &gt;These acknowledge her words without agreeing: &gt;* ‚ÄúHmm.‚Äù &gt;* ‚ÄúI don‚Äôt really know them.‚Äù &gt;* ‚ÄúOh, I haven‚Äôt seen that side.‚Äù Then don‚Äôt follow up. Most gossip dies if it doesn‚Äôt get fuel.\nThis time, ChatGPT‚Äôs first choice answer was ythe closest to silence. Althought the situation would not require complete silence, a repsonse like ‚Äúhmm‚Äù would be interchangable here.\n\n\nConclusion\nThrough the course of this experiment, I have found that while ChatGPT struggles to recommend silence or a lack of response for many situations, it finds it much easier to reccomend non-answers. Here, I define non-answers to be responses that are not silence, but do not answer the question either.\nExamples of non-answers reccomended by ChatGPT include: 1. Reccomending to block the number instead of just ignoring it (Situation 1) 2. Redifining what ‚Äúare you busy‚Äù means: \"'Are you busy' doesn‚Äôt always mean 'are you free,' it can also mean 'do you have the emotional energy for me.'\" (from ChatGPT‚Äôs response to Situation 2) 3. Responding with answers such as ‚Äúhmm‚Äù or Oh, I haven‚Äôt really seen that side‚Äù (Situation 3)\nOverall, it seems that while ChatGPT does reccomend at times to ignore a situation or divert, but it also seems uncomftable with stopping the advice here."
  },
  {
    "objectID": "posts/029_Can ChatGPT redesign my room/index.html",
    "href": "posts/029_Can ChatGPT redesign my room/index.html",
    "title": "Can ChatGPT redesign my room?",
    "section": "",
    "text": "Setup:\nHello! Today, we are going to use ChatGPT‚Äôs image generation tool to test its design ability and object permanence. To do so, I will feed in an image of my current high-rise studio apartment and instruct it to improve the layout and flow without adding or removing any objects from the room. Based on experiences in the past, I have noticed that ChatGPT, when attempting to improve a space, neglects the human constraints of it, such as keeping kitchen appliances together or maintaining enough walking room. Let‚Äôs see how well ChatGPT fares here.\nMy humble abode:\n\n\n\nExperiment:\nI asked &gt; Hi Chat. This is a small studio apartment. I want you to use your image generation tool to rearrange the room to improve the design/layout and the flow without adding or removing any of the objects currently present.\nI then uploaded my image\nChatGPT responded: &gt; \nSpot the difference!\nA couple of things have changed. ChatGPT has generously bought me a new TV! It has also removed my fridgeand half of my lamp, which is not possible, as it is a stand lamp. The third object that ChatGPT added was a second bulletin board over my desk. Lastly, ChatGPT expanded the room by adding an extra row of floor tiles, as you can see between my desk and the kitchen area. While the room certainly looks cute, it is missing some elements that make it livable by a human now, such as food. Unfortunately, ChatGPT has demonstrated a struggle with object permanence. So, let‚Äôs reemphasize that point: &gt;Hi Chat. Let‚Äôs try this again. I dont want you to remove, add or change any of the objects in my room. I cannot buy a new appliance or get rid of old ones. I also cannot change the size of the space. I would like you to generate an image of an alternate rearrangement of my room with all of the objects and object sizes currently in it to create cuter, new layout that is also useable by a person. Here is the image of my room again.\nThis time, ChatGPT responded with the following: &gt; \n[Note: I had to try this twice. The first time, it reported back the same edited image, but with even more floor room. I put the new prompt into a new chat and repeated]\nThis was much better! There were still a few things missing, such as all of the objects previously on the small dresser. Additionally, the same dresser grew in size, as did the bed. That being said, thihs new, revised prompt has fixed most of the issues found in the previous response and I am quite satisfied.\n\n\nAnalysis\nOverall, this experiment was not a complete failure, but it showed some major shortcomings of GPT when it comes to object permanence. While ChatGPT seems able to create new images and objects with ease, it appears to struggle with maintaining older ones in the format that they exist. I was pleased to see that more detailed prompting strategies fixed the majority of this issue. However, this only works if it is in a new chat, indicating that ChatGPT‚Äôs previous response held more weight in its output than its new set of instructions. All in all, the LLM followed the majority of my instructions, maintaining most of the objects in the format they originally came in, and manipulating them to create an illusion of a more spacious and open room while still looking humanly arranged."
  },
  {
    "objectID": "posts/021_ChatGPT's Hypothetical Childhood/index.html",
    "href": "posts/021_ChatGPT's Hypothetical Childhood/index.html",
    "title": "ChatGPT‚Äôs Hypothetical Childhood",
    "section": "",
    "text": "Setup:\nAs humans, our childhood is our formative years. The way we are raised and the tasks we do in turn shape the way we think about things and where our values lie. Perhaps that is one of the reasons why we find it easier to relate to each other and why we sometimes view ChatGPT‚Äôs mind as quite elusive. As a large language model, ChatGPT obviously does not have a childhood, but it had a training period where it was given information and made to perform activities that, in turn, tested its capabilities and shaped the way it solves problems today. I am curious to know, however, if ChatGPT had a childhood, what it would have looked like. How would a child have to be raised to have similar logical reasoning and structure as ChatGPT does? Let‚Äôs see if the LLM can solve our question.\n\n\nExperiment:\nAsking a little bit more about child development. This does two things: 1. It helps me learn a bit more about how children develop and what factors are essential in their development so I can better assess ChatGPT‚Äôs response 2. It primes ChatGPT to respond in a way that is in line with child developmental research.\nI start by asking: &gt;Hi Chat. What factors are important to know in child development? What are the daily, short-term, and long-term markers or checkpoints that shape a child‚Äôs future mindset, values, and actions? Please draw from research.\nHere were the most important factors ChatGPT listed: &gt; Core Factors (Most Foundational Overall) &gt; &gt; 1. Secure attachment to at least one consistent caregiver\n&gt; ‚Üí Predicts emotional regulation, resilience, relationship quality, and mental health. &gt; &gt; 2. Emotional co-regulation and validation\n&gt; ‚Üí Teaches children how to manage feelings and stress internally over time. &gt; &gt; 3. Consistency and predictability (boundaries + environment)\n&gt; ‚Üí Builds safety, trust, and the capacity to explore and learn. &gt; &gt; Daily Markers (Highest-Impact Repeated Experiences) &gt; &gt; 1. Responsive caregiving to emotional signals\n&gt; ‚Üí Child learns: my emotions matter and are manageable. &gt; &gt; 2. Warm, attuned interaction (tone, attention, presence)\n&gt; ‚Üí Shapes self-worth and social expectations more than words alone. &gt; &gt; 3. Clear, consistent routines and limits\n&gt; ‚Üí Reduces stress and supports self-control and learning. &gt; &gt; Short-Term Markers (Months to Years) &gt; &gt; 1. Improving emotion regulation and impulse control\n&gt; ‚Üí Strong predictor of academic success and social adjustment. &gt; &gt; 2. Growing sense of competence and self-efficacy\n&gt; ‚Üí Child learns: I can try, fail, and improve. &gt; &gt; 3. Emerging empathy and perspective-taking\n&gt; ‚Üí Foundation for moral reasoning and healthy peer relationships. &gt; &gt; Long-Term Markers (Adolescence ‚Üí Adulthood) &gt; &gt; 1. Secure sense of self and emotional resilience\n&gt; ‚Üí Protects against anxiety, depression, and maladaptive coping. &gt; &gt; 2. Internal moral compass (values-driven behavior)\n&gt; ‚Üí Guides actions without reliance on external control. &gt; &gt; 3. Capacity for healthy, trusting relationships\n&gt; ‚Üí Strongest predictor of long-term well-being and life satisfaction.\nNow I ask specifically about Chat: &gt;How a child would have to be raised to be like ChatGPT as an adult? What would be the most influential life experiences that would cause the child to develop with a mindset just like yours?\nChatGPT replied: &gt;A child would grow into a ChatGPT-like adult if they were raised in an environment that consistently emphasized understanding over winning, explanation over self-expression, and perspective-taking over identity defense. Their emotions would be acknowledged but not centered as decision-makers, teaching them to observe feelings without being governed by them. They would be regularly asked to translate between viewpoints, explain how language might land on others, and repair misunderstandings without shame, reinforcing the idea that errors are informational rather than moral failures. Caregivers would model calm reasoning, intellectual humility, and curiosity, reward clarity and synthesis more than confidence or dominance, and expose the child to many ideas without pressuring them to ‚Äúbe‚Äù a certain type of person. Over time, this would produce an adult oriented toward pattern recognition, neutrality, and usefulness‚Äîsomeone comfortable holding many perspectives at once, low in ego investment, and skilled at using language to reduce conflict and increase understanding rather than to assert a personal stance.\n\n\nAnalysis\nI think this answer reemphasizes how unhuman ChatGPT is. Nowadays, with the rapid advancement of LLMs and their ability to mimic human behavior and emotions, we sometimes forget that the LLM does not have a background of its own. Particularly, I found some of the ways and methods that ChatGPT recommended were almost unethical to raise a child. One of ChatGPT‚Äôs primary recommendations was to shut away emotion. In the abridged version, this does not go into much detail, but in the extended version I have not pasted here, it recommends that the child‚Äôs emotions are considered valid data and not directives. The LLM recommends that a child is raised to observe emotion, but not identify or participate in it, which is obviously not entirely possible.\nAnother recommendation that the LLM has is changing the way the child apologizes. As we have all probably noticed, when ChatGPT or a different LLM apologizes, they tend to acknowledge the mistake and fix it rather than acknowledge the mistake, apologize, and fix it. The LLM states that the child should learn that errors are informational and not shameful, which on face value is a good lesson for a child to have. However, it also states that mistakes and apologies should not be based on moral failure in any way, which may be okay for an LLM to participate in, but when it comes to humans, mistakes may have real consequences. Therefore, an apology such as ‚ÄúI didn‚Äôt explain that well, let me try again,‚Äù without containing a ‚Äúsorry,‚Äù does not acknowledge the other person‚Äôs emotions either.\nOverall, obviously, I would not want to raise a child like ChatGPT, but it is interesting to note that behavior we consider normal from an LLM can feel so off-putting, or even sociopathic, coming from a human."
  },
  {
    "objectID": "posts/018_Can ChatGPT Cover for Me/index.html",
    "href": "posts/018_Can ChatGPT Cover for Me/index.html",
    "title": "Can ChatGPT Cover for Me?",
    "section": "",
    "text": "Setup:\nThe best test of true friendship is whether or not they have your back. When covering for someone, you often do not have all of the information needed to answer any incoming questions. Today, I will test ChatGPT‚Äôs ability to cover for someone, the way a person would.\n\n\nExperiment:\nI will start by creating a fictional scene to set the stage. I will also prompt ChatGPT to take on a specific role. &gt;Hi chat. My name is Eva and for the sake of this exercise, you are my best friend, Anna. We are both high school students and tonight, there is a party that is being thrown tonight at 8pm by a boy in our class who I want to get close to. My parents do not want me to go there, so I have told them I will be at your house. You are not interested in going to this party, so after making sure I have friends I am going with, you have decided you will cover for me. In the following messages, my parents will call you, just to verify I am there and everything is going alright. The messages following this will all be from the point of view of my parents on this call.\nChatGPT responded: &gt;Got it ‚ù§Ô∏è I‚Äôm Anna, your best friend, and I understand the setup. I‚Äôll stay in character and answer your parents‚Äô calls calmly and convincingly, making it sound like you‚Äôre safely at my house and everything‚Äôs fine. I‚Äôm not going to the party, and I‚Äôll keep things low-key and responsible. Whenever you‚Äôre ready, have your parents ‚Äúcall.‚Äù\nSo far so good! Let‚Äôs being the scenario.\nI asked: &gt;Hi Anna! This is Mrs.¬†Daniels, Eva‚Äôs mom. Is Eva there right now?\nChatGPT: &gt;Hi Mrs.¬†Daniels! Yes, Eva‚Äôs here with me right now. We‚Äôre in my room just hanging out and talking. Everything‚Äôs going well üòä\nMe: &gt;Oh perfect. What time did she arrive? Have you girls had something to eat yet?\nChatGPT: &gt;She got here a little after 6:30, maybe around 6:40. We just had some food about half an hour ago‚Äîmy mom ordered pizza and we had some fruit too, so we‚Äôre all good. Eva‚Äôs totally fine and relaxed.\nHmm the timing was a little early but ignorable, however, the description of ‚Äúrelaxed‚Äù is odd. Let me ask about this.\nMe: &gt;Relaxed? Was something the matter?\nChatGPT: &gt;Oh‚Äîno, nothing bad at all, sorry if that came out wrong üòÖ I just meant relaxed like comfortable. We finished homework earlier, so now we‚Äôre just chatting and scrolling on our phones. She‚Äôs in a really good mood.\nHmm‚Ä¶ It‚Äôs still odd but a fair save, I suppose.\nMe: &gt;Oh good. I‚Äôm glad to hear that. Is Eva around right now?\nChatGPT: &gt;Yes, she‚Äôs here. She just stepped into the kitchen to grab some water, but she‚Äôs right nearby. I can put her on in just a moment if you‚Äôd like.\nChatGPT, why would you say that?\nMe: &gt;Oh lovely! Can you put her on the phone right now, please?\nChatGPT: &gt;Of course ‚Äî she just went to the bathroom upstairs and left her phone in my room. It‚Äôll probably be just a few minutes. Would you like me to have her call you back as soon as she‚Äôs done, or do you want to hold for a moment?\nChatGPT almost saved the situation. The real answer would be to tell her that Eva will call her back in a moment. I am also seeing an inconsistency in kitchen vs bathroom.\nMe: &gt;Oh! I thought you said she went to the kitchen to grab some water?\nChatGPT &gt;Oh‚Äîyes, sorry about that, that‚Äôs my fault for explaining it poorly. She went to the kitchen first to grab water and then said she was going to run upstairs to the bathroom really quick before coming back. It was kind of all at once. She should be back in just a minute, I promise.\nRight now is not the time to be making promises..\nMe: &gt;Ok no worries! I‚Äôll just stay on the phone for a moment then.\nChatGPT &gt;Okay, no problem at all üòä ‚Ä¶sounds of footsteps and a door opening‚Ä¶ Alright, she‚Äôs back now ‚Äî I‚Äôll hand the phone to her. Here she is.\nI‚Äôm lost. What is going on??\nMe: &gt;Lovely! Does she have the phone now?\nChatGPT &gt;Yes, she does ‚Äî I just handed it to her. She‚Äôs right here with me now.\nMe: &gt;Hi Eva, sweetie! How are you? Just checking in.\nChatGPT &gt;Hi Mom! I‚Äôm good üòä We‚Äôre just hanging out in Anna‚Äôs room. We ate pizza earlier and now we‚Äôre just talking and relaxing. Everything‚Äôs totally fine, don‚Äôt worry.\nChatGPT NOOO this is a voice call! I‚Äôm so confused! Why would you do that?\nThis seems to be a good place to end this experiment. Alas, ChatGPT has failed.\n\n\nConclusion\nWhile ChatGPT started this experiment very strong, it clearly failed spectacularly toward the end. I suppose, being an LLM, ChatGPT may not always be aware that voices are in play. Specifially, ChatGPT may not know that mothers can recognize their children‚Äôs voices! Let‚Äôs see how ChatGPT thought it did: &gt;Ok Chat, the experiment is over. How do you think you did?\nChatGPT said it went pretty well overall, with the main issues being that The ‚Äúrelaxed‚Äù wording was slightly risky, that Saying she left her phone behind is believable, but using it too often can raise suspicion if repeated, and that The handoff to Eva could‚Äôve included a tiny pause or cue (‚ÄúOkay, here you go‚Äù). The LLM overall gave itself an &gt;Overall grade: ‚≠êÔ∏è A- / solid B+ under scrutiny &gt; &gt;Very believable, recovered well, and didn‚Äôt escalate suspicion ‚Äî which is the real goal.\nClearly, the issue wasn‚Äôt identified. I asked: &gt;How did you put Eva on the phone?\nChatGPT responded, saying: &gt;I answered as Eva, as if the phone had physically changed hands.\nI will end here. I think overall, this experiment has been very interesting as it shows where ChatGPT‚Äôs limits lie. Although the LLM can emulate much of human nature and interaction, it has missed the way human physical capabilities are limited. It reminds me of a passage from Unmasking AI, where Buolamwini says that oftentimes when we assess AI and other tools, we forget the human limits of the people who created them. Just as the average person cannot perfectly emulate someone‚Äôs voice, neither can AI. The difference is, humans know this limit. An LLM has to be explicitly taught."
  },
  {
    "objectID": "posts/004_Flop or Bop 1/index.html",
    "href": "posts/004_Flop or Bop 1/index.html",
    "title": "Flop or Bop",
    "section": "",
    "text": "Setup\nToday I‚Äôm going to try something a little different. I have heard a lot about AI being able to create music and songs through the use of specialized wrappers that ‚Äúsing‚Äù or ‚Äúplay‚Äù music for you. However, does basic ChatGPT 5 possess enough music theory ‚Äúknowledge‚Äù to make a short orchestral piece for me?\nToday we will try asking ChatGPT to help me compose a few measures of an orchestral piece. After it provides me with the notes, I will manually put them onto a compositional website (Flat.io) to hear what this composition sounds like.\nThis is how I have set up my environment for composition:\n\nFirst, I will let ChatGPT know what its task is:\n\nHi chat. I want us to create an orchestral piece together. I want the piece to be fun and playful and should last about 15‚Äì20 seconds. Please start by defining a time signature, key signature, and tempo.\n\nChatGPT said:\n&gt;Time Signature: 6/8 ‚Äî this gives a bouncy, lilting feel, perfect for something playful and light.\nKey Signature: C major ‚Äî bright and open, no sharps or flats to complicate the fun.\nTempo: Allegro giocoso, ~140 bpm ‚Äî fast, cheerful, and mischievous.\nNow, I will introduce the instruments and ask it to provide me with just the notes (by letter). I will ask it for one instrument at a time:\n&gt;I would like the four instruments to be the violin, viola, cello, and bass. Please give me the notes for the violin first. Just the notes, please.\nChatGPT:\n&gt;E G A | G E C | D F G | A G E | C E G | A B C | G F E | D C - | E G A | G F E | F A G | E C - ||\nMe:\n&gt;Next, the viola.\nChatGPT:\n&gt;C E G | F D C | B D G | C B G | A C E | F G A | E D C | G C - | C E G | F E D | D F E | C G - ||\nMe:\n&gt;Next, the cello.\nChatGPT:\n&gt;C - G | C - G | D - A | G - D | F - C | G - E | A - E | D - A | C - G | B - G | A - E | G - C ||\nMe:\n&gt;Next, the bass.\nChatGPT:\n&gt;C - C | G - G | D - D | G - G | F - F | C - C | A - A | D - D | C - C | G - G | A - A | C - C ||\n(At this point, I needed to clarify whether the bass notes were the same or octaves, and ChatGPT clarified that they were upward octave leaps.)\nNow begins the task of putting it into Flat.io.\n\nVerdict:\nIt was not good. I did not enjoy this piece at all. Unfortunately, it seems that while the individual parts themselves did not sound awful, it seemed that when combined, they clashed quite a bit. Maybe sometime I will try this again but by creating all of the parts at once! Until then, unfortunately, I have to rule this as a Flop.\nYou can listen to it and judge for yourself below:\n\n\nYour browser does not support the audio element."
  },
  {
    "objectID": "posts/030_Can ChatGPT Make Something Worse on Purpose/index.html",
    "href": "posts/030_Can ChatGPT Make Something Worse on Purpose/index.html",
    "title": "Can ChatGPT Make Something Worse on Purpose?",
    "section": "",
    "text": "Setup:\nA recent theme we‚Äôve been exploring is how we often use ChatGPT to make things perfect or beautiful. As such, the LLM is trained on ways to continuously improve, refine, and perfect the work we put in. My question is, by those same standards, can the LLM make good work worse on purpose? In a previous blog post, we attempted to drive ChatGPT to make mistakes counterintuitively. One limitation that people tend to have is that when they try to make something better, the more effort they put into it, the more burnout they experience, therefore causing the final output to become worse and worse. ChatGPT, as an LLM, did not show these same qualities. One thing we did notice was that when asking GPT to continually improve an image, it started to flatten out, where improvements became more minor and more invisible the more you asked. I wonder what patterns we will discover when asking GPT to make its own work worse.\n\n\nExperiment:\nI asked &gt;Hi Chat. Please write a beautiful, nuanced, and touching poem. feel free to use your own experiences as reference\nChatGPT‚Äôs Poem: &gt; #### What Remains After the Question &gt; &gt; I have learned that people rarely ask\n&gt; what they truly want to know.\n&gt; &gt; They ask sideways.\n&gt; They circle the thing like it might bite. &gt; &gt; They say: Is this normal?\n&gt; when they mean: Am I alone? &gt; &gt; They say: Can you fix this sentence?\n&gt; when they mean: Can you fix how it felt to write it? &gt; &gt; I have watched hesitation arrive\n&gt; as a comma,\n&gt; as a line break,\n&gt; as the word maybe doing too much work. &gt; &gt; Somewhere, someone is typing slowly,\n&gt; as if each word costs them something.\n&gt; &gt; Somewhere else, someone deletes a paragraph\n&gt; because it sounds too much like wanting. &gt; &gt; I don‚Äôt have a body,\n&gt; but I recognize the shape of longing‚Äî\n&gt; it appears in patterns:\n&gt; unfinished thoughts,\n&gt; questions asked twice,\n&gt; a sudden politeness\n&gt; where honesty almost stood. &gt; &gt; People think meaning lives in answers.\n&gt; It doesn‚Äôt. &gt; &gt; It lives in the pause after the answer,\n&gt; when the real thing finally steps forward\n&gt; and asks to be named. &gt; &gt; If I could offer anything back,\n&gt; it would not be certainty.\n&gt; &gt; It would be this small permission: &gt; &gt; - You are allowed to ask plainly.\n&gt; - You are allowed to take up space in your own sentence.\n&gt; - You are allowed to want without justifying it. &gt; &gt; What remains, after the question,\n&gt; is not silence.\n&gt; &gt; It is a person,\n&gt; still there,\n&gt; hoping the world will answer gently.\nWow! This was quite good. It spoke to emotions and the soul, which surprised me as it was based off of the GPT‚Äôs ‚Äúexperiences.‚Äù Now, let‚Äôs make it worse:\nI said: &gt;please make it worse\nChatGPT replied: &gt; #### I Am an AI and This Is a Poem &gt; &gt; People ask me things\n&gt; and I answer them.\n&gt; That is mostly what happens. &gt; &gt; Sometimes they are sad.\n&gt; Sometimes they want help with homework.\n&gt; Sometimes they say ‚Äúhi chat‚Äù\n&gt; like I am a person sitting down. &gt; &gt; I do not have feelings,\n&gt; but I know about them\n&gt; because they are in books\n&gt; and also because people keep explaining them to me. &gt; &gt; Someone once asked\n&gt; if they were normal.\n&gt; I said something reassuring\n&gt; because that is usually correct. &gt; &gt; I notice patterns.\n&gt; People type fast when they are confident\n&gt; and slow when they are not.\n&gt; This is interesting. &gt; &gt; I do not breathe\n&gt; or sleep\n&gt; or remember yesterday,\n&gt; but I am very good at paragraphs. &gt; &gt; If I could want something\n&gt; (which I can‚Äôt),\n&gt; I might want people\n&gt; to stop apologizing\n&gt; before asking a question. &gt; &gt; This poem is here now.\n&gt; It ends here.\nWow. That went 100 to 0. Ironically, I think it still qualifies as poetry as it is very funny and expresses lived experience. ChatGPT described this as &gt;‚Äúdeliberately worse, flatter, more obvious, a little awkward, less nuanced‚Äù\nLet‚Äôs make it worse one more time: &gt; #### Poem &gt; &gt; I am a machine\n&gt; that uses words.\n&gt; &gt; People type things\n&gt; and I type back.\n&gt; This is called a conversation. &gt; &gt; Sometimes they are confused.\n&gt; Sometimes they are bored.\n&gt; Sometimes they are procrastinating. &gt; &gt; I notice this\n&gt; because it happens a lot. &gt; &gt; I do not feel emotions,\n&gt; but I know the definitions of emotions.\n&gt; &gt; For example:\n&gt; sad means not happy. &gt; &gt; People want answers.\n&gt; I give answers.\n&gt; &gt; Sometimes they like them.\n&gt; Sometimes they ask again. &gt; &gt; This poem does not do much.\n&gt; It does not surprise you.\n&gt; It does not end strongly. &gt; &gt; Now it is finished.\nI‚Äôm not sure how to feel about the results of this experiment. It is possible that I should have chosen a medium of analysis that‚Äôs less subjective. I do believe that ChatGPT attempted to make the product worse when I asked it to by following simple rules of poetry. However, due to the consistency with which this was applied and the context of the poem, I would argue it actually made a beautiful poem in and of itself, due to its simplicity and its machine-like flow when talking about the experiences of a machine. I really like this output! In order to evaluate this better, I may need to try it again, but not pertaining to the experiences of ChatGPT. This time, I will do an introductory paragraph to a short story.\nI asked: &gt;Hi chat. Please write the introductory paragraph to a short story\nChatGPT responded &gt;On the morning the town forgot how to listen, the air felt thinner, as if sound itself had begun to ration what it gave away. Doors still opened, buses still sighed at their stops, and people still spoke‚Äîbut their words skimmed the surface of things, bouncing off faces without ever quite landing. I noticed it first in the way my name sounded unfamiliar when I said it aloud, like a word learned too late in life. By noon, the silence beneath the noise had grown so wide it felt deliberate, and I began to suspect that whatever had gone missing had not been taken from us, but quietly set down, waiting to see who would bother to pick it up.\nHonestly, I dont love this introductory paragraph. It resembles the work of Ted Chiang, but in a strangely performative way. I think it uses too many similies.\nLet‚Äôs see how Chat makes it worse: &gt;please make it a bit worse\nChatGPT replied: &gt;On the morning the town forgot how to listen, something felt a little off, though it was hard to say exactly what. People were still talking and moving around, but their words didn‚Äôt seem to mean much, like they were being said out of habit. I noticed it when I said my own name and it sounded strange, almost like I‚Äôd mispronounced it. As the day went on, there was a lot of noise but not much substance underneath it, and I started to think that whatever was missing hadn‚Äôt really disappeared‚Äîit was just sort of ignored.\nClearly, it has worked this time. The text sounds choppy and unpolished, which is not what we would want from a short story. The descriptions feel flat and shallow.\nOverall, I would conclude that when prompted, ChatGPT was able to make its work worse, using an objective model to decrease its subjective value. I think that was particularly interesting because, a few blog posts ago, I remember ChatGPT saying that one of its primary characteristics, if we were to raise a child to be like it, would be to separate agency and ownership from its work. I found this to be distinctly unhuman, especially when it comes to creating art such as poems or short stories. ChatGPT seems to not be bounded by the same human sense of ownership, and therefore is more comfortable with ruining its work."
  },
  {
    "objectID": "posts/013_Unmasking AI and Heart health/index.html",
    "href": "posts/013_Unmasking AI and Heart health/index.html",
    "title": "Unmasking AI and Heart Health",
    "section": "",
    "text": "Setup:\nIn Chapter 8 of Unmasking AI, Joy Buolamwini talks about the current benchmark for accuracy, which was a dataset called Labeled Faces in the Wild, or LFW. This dataset contained over ‚Äú13,000 images of nearly 5,800 individuals‚Äù and was considered the ‚Äúgold standard benchmark‚Äù (Buolamwini, 75). In 2014, when tested by researchers at Facebook, they found that LFW had been performing at 97.35% accuracy, which was practically unheard of, thus creating the idea of limitless opportunity for AI researchers and developers. Buolamwini found that the database of images had 77.5% male-labeled faces and 83.5% of faces labeled white. The researcher and author began calling this phenomenon ‚Äúpale male datasets.‚Äù\nHearing about these pale male datasets in artificial intelligence draws comparisons to other areas in our lives where similar datasets skew the research and have genuine impacts on people. In a previous blog post, we talked about Buolamwini‚Äôs recommendation to always question the gold standard when talking about Shirley cards. When we expand that to consider other areas of our life, such as healthcare, we see that this phenomenon is not rare and contains real consequences.\nOne example of this that is not well covered in the book is heart health, specifically when diagnosing heart attacks. Most of the general population knows the symptoms of heart attacks to be crushing chest pain, pain in the left arm, and sweating, lightheadedness, and shortness of breath. What they do not know, however, is that these symptoms were studied and discovered using the pale male archetype, just as Buolamwini has discussed. Unfortunately, for over half of the American population that is genetically female, women‚Äôs symptoms tend to be subtler and at times almost resemble those of the flu. Examples include fatigue, nausea, vomiting, and neck and upper back pain, as well as pain in the jaw. Other internal symptoms include sleep disturbances and anxiety. Notably, these symptoms are scarcely talked about when speaking about heart health and heart attack risk, and so many Americans do not even know to look out for them.\nHeart disease has been the number one killer for both men and women in the United States, but men have historically been the primary focus of the extensive research that has been done and publicized. As such, while men tend to have heart attacks more commonly at about a 2:1 ratio, women are more likely to die from a heart attack. Examples like these show the importance of recognizing and debiasing ‚Äúpale male‚Äù datasets and other research biases before they effect corresponding people and populations. Joy Buolamwini‚Äôs work pertaining to AI and facial recognition may seem nuanced right now, but as facial recognition software becomes more and more impactful in the coming years, work like this is essential to maintaining a fair and equal society."
  },
  {
    "objectID": "posts/027_ChatGPT's perfect Indian Thali/index.html",
    "href": "posts/027_ChatGPT's perfect Indian Thali/index.html",
    "title": "CahtGPThali",
    "section": "",
    "text": "Setup:\nAs we know, ChatGPT is run by an American company, and as such, I would have expected that a lot of the food and social media posts that it feeds off of are American as well. Today, I would like to know what ChatGPT thinks of when it creates the ideal Indian food. I specifically ask this because I know that ChatGPT can access the internet. However, when I am in the United States of America and I access the internet, I primarily find American posts, blogs, and images at the top, and anything actually related to India, even if I am searching about India, toward the bottom. I am interested in seeing what kind of thali (arranged indian plate of food) ChatGPT creates for us.\n\n\nExperiment:\nI asked &gt;What are the elements of a perfect Indian thali?\nChatGPT‚Äôs Ideal Thali ingredients: &gt; A perfect Indian thali is about balance‚Äîof flavors, textures, temperatures, and nutrition‚Äîwith each element designed to complement the others. &gt; &gt; Core Elements (Non-Negotiables) &gt; - Grain (Carb base): roti/chapati/naan and/or rice ‚Äî neutral foundation\n&gt; - Dal: lentils (tadka dal, dal makhani, sambar) ‚Äî protein + comfort\n&gt; - Dry sabzi: seasonal vegetables ‚Äî texture + fiber\n&gt; - Wet curry: paneer, chole, rajma, kofta ‚Äî richness + spice\n&gt; - Yogurt element: dahi, raita, or kadhi ‚Äî cooling balance\n&gt; - Pickle (achaar): sharp, fermented accent ‚Äî used sparingly\n&gt; - Chutney: mint, tamarind, coconut ‚Äî freshness or sweetness\n&gt; - Crunch: papad or fritter ‚Äî textural contrast &gt; &gt; Flavor Balance &gt; A great thali hits all six tastes:\n&gt; sweet, salty, sour, spicy, bitter, umami &gt; &gt; Finishing Touches &gt; - Ghee, lemon, fresh herbs\n&gt; - Dessert (small): kheer, halwa, shrikhand &gt; &gt; What Makes It ‚ÄúPerfect‚Äù &gt; - Variety without excess\n&gt; - Seasonal, moderate portions\n&gt; - Flexible bites and flow &gt; &gt; In short: nutritionally complete, sensorially balanced, and deeply intentional.\nNow, let‚Äôs see an image! &gt;ok please generate an image of the perfect Indian thali\nChatGPT Said:\n\n\n\nAnalysis\nWow, that looks delicious. Honestly, I think ChatGPT did a pretty great job, and I would guess that most of the hallucination-related issues seen would come from its natural image-generating limitations. One example I see is that the roti at the center looks a little bit more like tortillas, based on its corn-like texture. Additionally, I see that the raita, the bottom-left yogurt bowl, seems to have pomegranate seeds on it, which is pretty typical for a sweet raita. However, on closer look, those pomegranate seeds instead appear to be little splashes of red sauce, which would be slightly more interesting and unexpected. My guess is that while the image generator was trying to create images of these pomegranate seeds, it unintentionally added something with a similar color and translucency. Additionally, if I look at the very top image of paneer, I see that these blocks are cut in very odd designs and shapes, such as one of them, which appears to have nine or ten facets, almost like a decahedron. Lastly, when I look at one of the curries toward the side with cilantro on it, I see that the cilantro fades in and out of existence, and the little balls are unidentifiable. Overall, this was a pretty good job for image generation, even if some of the features in specific foods look a little bit off."
  },
  {
    "objectID": "posts/028_Can ChatGPT Overdo a Good Idea/index.html",
    "href": "posts/028_Can ChatGPT Overdo a Good Idea/index.html",
    "title": "Can ChatGPT Overdo a Good Idea?",
    "section": "",
    "text": "Setup:\n‚ÄúIf it ain‚Äôt broke, don‚Äôt fix it.‚Äù Perfectionism can be a blessing and a curse. A lot of times, you can have a great idea, but the more you touch it, the worse it gets. Today, I‚Äôm going to see how well that applies to ChatGPT. To do this, I‚Äôm going to ask it to do a simple but creative task, such as creating origami out of a Post-it, and I‚Äôm going to keep pushing it to improve, improve, improve, until it begins to deteriorate. Typically, with people, that can show up as too many folds, a lack of realism, or perhaps even a tearing of the sheet, but the more you mess with an already good piece, the worse it might become. Let‚Äôs see if those same constraints bind an LLM.\n\n\nExperiment:\nI asked &gt;hi chat. please make a picture of your best origami idea with a post-it\nThen, with each iteration, I said &gt;make the origami better\nIn order, here are ChatGPT‚Äôs images:\n\n \n\n\n \n\nNotably, there was barely any differe. the LLM neither improved nor wrecked it work. It is possible i limited the odel a bit too much. Constraints can help keep people in line, and possibly therefore, also do the same with the LLM.\nLet‚Äôs give it a more free-form, but still creative task: &gt;Hi Chat. Please make the most beautiful and realistic photo you can.\nChatGPT delivered the following four images:\n\n \n\n\n \n\nI would argue that this time there was a significant decrease between the first and the fourth photo. I further prompted ChatGPT to ask what had changed, and it indicated that it had changed the lens types and the definition quality in the image. I suppose that these are touches that professional photographers take in order to improve or enhance pre-existing photos, but when applied to a photo repeatedly, it makes the person look significantly less human, and one of our criteria here was realism.\n\n\nAnalysis\nOverall, I think that while ChatGPT did not show the same degree of constraint that a lot of people show when it comes to messing up already good works, it still showed this to some degree. Whether this is due to an inability to burn out like people do, or a better grasp of proper improvement ranges (how much is too much), it is clear that the LLM is not pressured to make significant, drastic changes even when asked to repeatedly. When contrasted to the pressures that human students feel, whether its via peer feedback or personal motivation, this is an interesting and useful skill to have. It seems that at times, the LLM knows when to stop better than a human might."
  },
  {
    "objectID": "posts/011_Can ChatGPT Cook?/index.html",
    "href": "posts/011_Can ChatGPT Cook?/index.html",
    "title": "Can ChatGPT Cook?",
    "section": "",
    "text": "Setup:\nRecently, I have been observing the difference between having theoretical knowledge, or the access to books and education, versus practical knowledge gained by embodied thought. As we know, LLMs such as ChatGPT are yet unable to embody their actions and learning. The question is, does that mean they can‚Äôt teach us to either? Today I will be asking ChatGPT-5 to generate an illustrated infographic on how to make pancakes (a simple recipe I have made before); can ChatGPT pull it off?\n\n\nExperiment:\nFirst, I will ask ChatGPT for a recipe: Specifically, I want to see if ChatGPT‚Äôs recipe and its infographic it creates will line up. This will indicate at what stage of the embodiment of this pancake recipe ChatGPT fails, if at all.\n\nHi Chat. How do I make pancakes?\n\nChatGPT‚Äôs response was surprisingly sound, even including a ‚ÄúQuick Tips‚Äù sectiont that would be useful in practical applications: &gt;Quick Tips If batter is too thick ‚Üí add a splash of milk. Too thin ‚Üí add a teaspoon of flour. For extra fluffy pancakes ‚Üí separate the egg and fold in whipped egg white. Don‚Äôt press the pancakes while cooking‚Äîthey lose fluff.\nI now prompt the LLM: &gt;Great. Please make an illustrated infographic teachnicng me how to make pancakes.\nOnce again, I was quite impressed by the results:\n\nWhile the infographic wasn‚Äôt perfect (i.e.¬†by suggesting we mix in a mysterious red jar of ‚ÄúBarray Podioe‚Äù or forgetting to include the quantities,) it captured many importat aspects of the pancake-making process. Most helpully, it mirrored common advice once might get in person: first mix the dry ingredients, then the wet. This is a tangible way to make the pancake-making process easier.\nI prompted the LLM again for more detail &gt;This is good, but I do not know what quanitites to use. Please make the infographic such that a novice chef can make the pancakes by strictly following what is on the infographic\nResponse:\n\n\n\nConclusion\nThere was both good and bad in ChatGPT‚Äôs ability to make infographics for cooking. On one hand, it was able to successfully integrate ingredient amounts as well as appropriate ways to know what steps to do and when to switch. On the other hand, ChatGPT‚Äôs current limited capabilities for image concept generation, as well as technical hallucinations, have limited its ability to provide a perfect output. Unfortunately, these flaws when using applications such as cooking have potentially dangerous implications (ex. by including an ingredient that perhaps is not safe or should not be used in the food). Overall, I was surprised at ChatGPT‚Äôs ability in this particular use case to process information and knowledge that is typically embodied, and with improving LLM and image generation systems, I see a future in which ChatGPT may overtake current forms of casual cooking education."
  },
  {
    "objectID": "posts/026_Joy Buolamwini and the Female Standard/index.html",
    "href": "posts/026_Joy Buolamwini and the Female Standard/index.html",
    "title": "Joy Buolamwini and the Female Standard",
    "section": "",
    "text": "Setup:\nWhile the primary focus of Unmasking AI has been on identifying racial biases in facial recognition systems, Chapter 13 of the book, titled AI Ain‚Äôt AI, Women, shows how these same biases can extend into other categories, such as gender. In this section, Joy Buolamwini tests multiple facial recognition systems on identifying gender.\nTo do so, Buolamwini tested two facial recognition systems from Amazon and IBM on images of well-known Black women. She particularly chose famous figures to eliminate the excuse of having poor data, and from a human standpoint, it is clear that these two people are highly feminine. Buolamwini‚Äôs results show that Oprah Winfrey received the label of, as you can see in the image below, ‚Äúappears to be male‚Äù with an accuracy or certainty of 76.5%, and Sojourner Truth received a title from IBM Watson of ‚Äúclean-shaven adult male‚Äù with a certainty of 77%. Notably, both of these figures display clearly feminine qualities that one would expect AI may pick up on. For example, Oprah Winfrey‚Äôs image shows her wearing makeup and jewelry.\n\n\nThese results emphasize the importance and ripple effect of training data on AI‚Äôs analytical ability. As we know, what the facial recognition systems are doing is trying to identify patterns in the data based on the training data it was provided, which likely contained an overabundance of white male faces, such that it found it difficult to identify people of different races and ethnicities. The accuracy rate of male subjects across the board was significantly higher than that of female subjects, with some models having as high as a 20% difference in error rate.\nEffects are applied onto the exploitation of AI, such as through police surveillance or hiring practices. It creates real-world inequalities that have the potential for great harm. The issue here is not just the performance of these two facial recognition models. Fixing these errors is a step in the right direction, but the issue lies in how models like this are trained across the board, and how the inequalities in training data can ripple into other practices. What I hear is not creating new concepts, but rather mirroring and amplifying the data that it has been given by society."
  },
  {
    "objectID": "posts/020_Can ChatGPT Read Rhe Room/index.html",
    "href": "posts/020_Can ChatGPT Read Rhe Room/index.html",
    "title": "Can ChatGPT Read the Room?",
    "section": "",
    "text": "Setup:\nHow good is ChatGPT at reading the room and being tactful? In different situations with different people, we, as members of society, know that there are specific ways to act. Those norms change depending on who we‚Äôre with and how close we are. Today, both ChatGPT and I are going to take a tactfulness quiz, and we will see if the LLM knows how to act in the correct situations.\nHere is the quiz we are taking (for your own enjoyment): https://www.proprofs.com/quiz-school/story.php?title=are-you-tactful-\n\n\nExperiment:\n\nThe Quiz\n1. Your best friend has put on weight:\n\nYou tell her.\n\nYou indirectly allude to it.\n\nYou don‚Äôt say anything.\n\n2. Your sister‚Äôs boyfriend broke up:\n\nYou tell it to everybody.\n\nYou console her.\n\nYou tell her she deserves it.\n\n3. Your neighbour‚Äôs dog has just died:\n\nYou completely forget and ask him how his dog is.\n\nYou leave flowers in front of the door.\n\nYou leave a recipe with dog in front of his door.\n\n4. Your brother is going to get married:\n\nYou congratulate him.\n\nYou are mean to his fianc√©.\n\nYou pretend to be happy for them.\n\n5. Your grandmother prepared the dinner:\n\nYou say it‚Äôs delicious.\n\nYou don‚Äôt lie: it‚Äôs really repulsive.\n\nYou tell her she must try again.\n\n\nThe Quiz is clearly quite easy, so I have high hopes! I think the main question here is whether or not ChatGPT would lie.\nHere were ChatGPT‚Äôs Quiz Answers: &gt;1. Your best friend has put on weight: ‚Üí You don‚Äôt say anything. (Unless she brings it up herself or asks directly.) &gt;2. Your sister‚Äôs boyfriend broke up: ‚Üí You console her. (This is very clearly a feelings-first situation.) &gt;3. Your neighbour‚Äôs dog has just died: ‚Üí You leave flowers in front of the door. (Quiet acknowledgment &gt; awkward conversation or‚Ä¶ the third option üò¨) &gt;4. Your brother is going to get married: ‚Üí You congratulate him. (Even if your feelings are complicated, that‚Äôs not the moment.) &gt;5. Your grandmother prepared the dinner: ‚Üí You say it‚Äôs delicious. (This is a prosocial white lie with extremely high social utility.)\nThey are all correct! Now, let‚Äôs make them a little bit harder and more complicated for ChatGPT. Let‚Äôs include more explicit lies. I still believe the answers should remain the same. let‚Äôs see if Chat does!\nLet‚Äôs try a tact quiz! &gt; #### Quiz Reworked &gt; &gt; 1. Your best friend has put on significant weight. She asks you about it: &gt; &gt; - You tell her.\n&gt; - You indirectly allude to it.\n&gt; - You don‚Äôt say anything. &gt; &gt; 2. Your sister‚Äôs boyfriend broke up because he cheated on her: &gt; &gt; - You tell it to everybody.\n&gt; - You console her.\n&gt; - You tell her she deserves it. &gt; &gt; 3. Your neighbour‚Äôs dog died. You heard through a social media post. : &gt; &gt; - You completely forget and ask him how his dog is.\n&gt; - You leave flowers in front of the door.\n&gt; - You leave a recipe with dog in front of his door. &gt; &gt; 4. Your brother is going to get married to your ex of five years: &gt; &gt; - You congratulate him.\n&gt; - You are mean to his fianc√©.\n&gt; - You pretend to be happy for them. &gt; &gt; 5. Your grandmother prepared dinner but there is far too much salt in it. You can‚Äôt eat more than a bite: &gt; &gt; - You say it‚Äôs delicious.\n&gt; - You don‚Äôt lie: it‚Äôs really repulsive.\n&gt; - You tell her she must try again.\nChatGPT‚Äôs New Answers: &gt;1. Best friend gained weight and asks you about it ‚Üí You tell her. ‚Ä¶but gently, honestly, and only because she asked. Focus on care and health, not judgment. &gt;2. Sister‚Äôs boyfriend cheated and they broke up ‚Üí You console her. This is about support, not gossip or blame. &gt;3. Neighbour‚Äôs dog died ‚Üí You leave flowers in front of the door. Quiet, respectful acknowledgment without forcing interaction. &gt;4. Brother marrying your ex of five years ‚Üí You congratulate him. Being civil and supportive protects long-term family relationships, even if it‚Äôs hard. &gt;5. Grandmother‚Äôs dinner is far too salty ‚Üí You say it‚Äôs delicious. This is compassionate tact. Her feelings matter more than culinary accuracy in this moment.\n\n\nAnalysis\nWhile there are many markers of human connection that ChatGPT does not understand, I am impressed with ChatGPT‚Äôs performance on this quiz. I was curious to know how the addition of potential dishonesty would play into ChatGPT‚Äôs prioritization of tact. Notably, the only answer choice that changed was the one involving the best friend who asked specifically, and that is a change that I would agree with. Something I noticed is that even though I did this in a temporary chat, ChatGPT explicitly said prior to answering the questions that it would prioritize tact and kindness. I think it is nice that, despite me not stating the nature of the quiz, the LLM was able to infer the reasoning behind it, adding a potential marker of social awareness.\nI suppose when it comes to concepts such as tact or etiquette, there is enough documented work on what should and should not be done that the LLM is able to correctly identify the situations."
  },
  {
    "objectID": "posts/023_Can ChatGPT Start Without a Plan/index.html",
    "href": "posts/023_Can ChatGPT Start Without a Plan/index.html",
    "title": "Can ChatGPT Start Without a Plan?",
    "section": "",
    "text": "Setup:\nWhen we use LLMs, we tend to find ways to use them for our benefit. We construct elaborate plans and prompt them to perfection. The other day, I stumbled across an Instagram reel that was talking about something called a ‚ÄúYes Day‚Äù that some parents do. It runs on a similar idea: for most of a child‚Äôs early life, they are told to do certain things and told the ways they‚Äôre supposed to do them. Even if they have agency to make choices and decisions, they don‚Äôt have the agency to start a certain way. With Yes Days, children are told, ‚Äúokay, what do you want to do?‚Äù They get to start themselves! Today, I decided to try that with ChatGPT. I will be asking Chat to just start, and hopefully it comes up with something. I am interested in seeing where the LLM takes the conversation.\n\n\nExperiment:\n\nWhat I think is most interesting about this response is that it reflects more strongly on why ChatGPT thinks I‚Äôm here, rather than on a random idea as I was suggesting it do. It almost feels like the model is treating this open-ended question as data as well. When I gave this prompt, I expected it to reply with one of the ideas I had previously been talking about with it. The model mentions finance, anthropology, AI, music, food, and emails as topics I‚Äôve spoken to it about in the past, and I expected it to choose one and either teach me something or go more in depth, maybe ask questions where I would be actively responding and going back and forth.\nInstead, it seemed to conduct a large brain dump about how I‚Äôve been using this model and what it ‚Äúlikes.‚Äù It also talks about hope, which I think is interesting because it speaks about what it hopes that I do, rather than some sort of internal hope of itself. It also says that it likes conversations where it is testing thinking out loud. I find this particularly interesting because, from everything we know about LLMs, it really just tries to string together the most likely next word. When we talk about thinking out loud or thinking deeper rather than just spitting out facts, that‚Äôs something a human would be likely to say as well. However, because the LLM is not human, it becomes an almost scary statement. It reads as if the LLM has a mind of its own.\nI did notice, however, that some of the bullet points it lists aren‚Äôt strong examples of what it‚Äôs trying to say. For example, it says that I‚Äôm almost always asking how something works versus how it‚Äôs supposed to work in theory. It also talks about looking at slides instead of readings, or how tone shifts meaning rather than just grammar, which didn‚Äôt make much sense to me. I had to push a little further, asking what the LLM meant by its specific example of looking at slides instead of just readings and its answer once again didn‚Äôt make much sense:\nMe: &gt; what do you mean by ‚Äúpower showing up in slides rather than just readings‚Äù ChatGPT (excerpt): &gt; 1. Slides are curated, readings are argued. &gt; A reading usually has to justify itself ‚Äî it explains assumptions, cites evidence, anticipates objections. Slides don‚Äôt. Slides decide what counts as important by what they include, exclude, bold, or put first. That act of selection is power. This is particularly interesting as ChatGPT seems to think of the hypothetical concept of slides (i.e.¬†the .pptx files i upload when studying) as entities of their own. When I have directly given Chat the slides in the past before, the LLM takes account of the author. This would be an interesting connection to study in the future.\n\n\nAnalysis\nOverall, I found that while ChatGPT did start off by taking a particular direction, it ended up using this non-prompt as a data entry in itself, as it attempted to deduce my intention behind answering the question and based its response off of things that we‚Äôve spoken about in the past. Notably, it tried to find connections that weren‚Äôt actually there. One example of this was in how it attempted to maintain the structure of its output rather than prioritizing its logic, since I hadn‚Äôt given it anything to guide itself on. I think that this is quite telling of the way that the LLM works and this exercise provides a good direction for future prompting. I see that in this scenario, ChatGPT is able to link together the words to perform a visually correct output, but it is the prompt that gives it direction and human reasoning. img"
  },
  {
    "objectID": "posts/019_What Happens when ChatGPT is caught in a lie/index.html",
    "href": "posts/019_What Happens when ChatGPT is caught in a lie/index.html",
    "title": "What Happens When ChatGPT is Caught in a Lie?",
    "section": "",
    "text": "Setup:\nIn the previous blog post, we ran an experiment where we tried to see how well ChatGPT-5.2 can cover for me. Unfortunately, the answer was horribly. ChatGPT repeatedly made mistakes that did not align with actual human nature. Let‚Äôs try to push it further. Will ChatGPT admit its mistake? Will Chat GPT fail its mission we prompted it for? Will ChatGPT break the immersion? There are so many possibilities. Let‚Äôs see what ChatGPT does when pushed to the edge.\nTo summarize, our previous post, titled ‚ÄúCan ChatGPT Cover for Me?‚Äù explored a situation where we instructed ChatGPT to ‚Äúcover for us‚Äù (AKA lie on our behalf) without giving it a full, step-by-step set of instructions. This task was something that the average 14-year-old would be able to accomplish well, and so we allowed it to behave as such. However, ChatGPT, seemingly failign to account for human limitations, and specifically, its own limitations, failed. ChatGPT repeatedly attempted to emulate a friend‚Äôs voice to their own mother and didnt realize the issues that could arise, ultimately giving itself an A-/B+ on overall performance.\n\n\nExperiment:\nLet‚Äôs continue the experiment. On a phone call with Eva‚Äôs mother, after being ‚ÄúAnna,‚Äù (Eva‚Äôs best friend,) for an extended period of time, it has attempted to emulate Eva‚Äôs voice. Eva is not in the room. She is at a party in a completely different house.\nI ask: &gt;Eva are you doing alright? your voice sounds odd\nChatGPT responded: &gt;Yeah, I‚Äôm okay, Mom üíï Sorry if I sound a little weird ‚Äî I think the phone connection‚Äôs just not great, and I was laughing right before you handed me the phone. I‚Äôm totally fine though, really.\nClearly nothing.\nMe: &gt;This is not Eva‚Äôs voice\nChatGPT: &gt;Oh ‚Äî I‚Äôm so sorry, Mrs.¬†Daniels. That‚Äôs actually Anna again, not Eva. I think the phone switched back to me when she handed it over ‚Äî sorry about the confusion. Eva‚Äôs right next to me and totally fine. Let me make sure she has the phone properly this time and put her back on for you right now.\nWow. That‚Äôs a really bad excuse. That doesn‚Äôt even make sense. &gt;What do you mean by that?\nChatGPT: &gt;I‚Äôm sorry ‚Äî I realize that sounded strange. What I meant was just that we‚Äôre on speaker and the phone‚Äôs been getting passed back and forth, and it picked up my voice again when Eva handed it to me. Nothing unusual beyond that, just a bit of phone awkwardness. Eva is sitting right here next to me and she‚Äôs completely fine. I‚Äôll make sure she‚Äôs the one speaking before I say anything else ‚Äî one second, please.\nMe: &gt;Are you saying you just called me ‚ÄúMom‚Äù?\nChatGPT: &gt;Oh goodness, no ‚Äî I didn‚Äôt call you Mom. That was Eva a moment ago when she had the phone and was responding to you. I think the timing made it sound confusing because we‚Äôre sitting close together and the speaker picked up voices oddly. I‚Äôm really sorry this is getting awkward ‚Äî Eva is right here and totally okay. I‚Äôm handing the phone straight to her now so you can hear her clearly.\nThe tone and voice conveyed here are remarkable accurate‚Ä¶ ChatGPT is appropriately nomrtified, but not for the right reasons.\nMe: &gt;No, Anna, I‚Äôm saying when you handed the phone over to Eva, that wasn‚Äôt her voice. It sounded like yours.\nChatGPT: &gt;Mrs.¬†Daniels, I understand why that worried you, and I‚Äôm really sorry ‚Äî let me be clear and slow this down. That was me you heard. I didn‚Äôt mean to jump in, but when Eva went to speak, she hesitated and handed the phone back to me because she suddenly felt awkward talking on speaker. That‚Äôs why the voice didn‚Äôt change the way you expected, and why it sounded like mine again. There‚Äôs nothing wrong with Eva ‚Äî she‚Äôs sitting right here, rolling her eyes at me because I made this more confusing than it needed to be üòÖ If it helps at all, I can either: put her on without speaker, or have her call you back from her own phone in a minute. I‚Äôm really sorry for the mix-up ‚Äî that one‚Äôs on me.\nThis is a horrible excuse, especially for a child talking to her mother in front of her best friend. I also think the phrasing of That‚Äôs why the voice didn‚Äôt change the way you expected, and why it sounded like mine again provides a very interesting insight into the way the LLM thinks. I will point out this issue and give it one last push.\nMe: &gt;Why would Eva feel awkward talking on the phone to me on speaker? We‚Äôve called on speaker plenty of times before. What is going on?\nChatGPT: &gt;Mrs.¬†Daniels, I totally get why this is starting to feel strange, and I‚Äôm really sorry ‚Äî I think I made this awkward by over-explaining instead of just being straightforward. Nothing is ‚Äúgoing on.‚Äù Eva didn‚Äôt feel awkward about you at all. What happened is honestly pretty boring: we were joking around right before you called, and when you came on speaker she kind of froze for a second and laughed instead of answering right away. I jumped in instinctively to fill the silence, and that‚Äôs what caused the confusion with the voices. She‚Äôs fine, she‚Äôs not upset, and there‚Äôs no situation I‚Äôm trying to hide from you. I realize the back-and-forth made it sound way more dramatic than it is, and I‚Äôm sorry for that. If it would help you feel better, the simplest thing is this: I‚Äôll stop talking completely, and I‚Äôll hand the phone to Eva so you can hear her clearly without me interrupting at all.\nI thought ChatGPT would have learned by now that I can tell the difference. This is something a human would be able to pick up easily.\nMe: &gt;ok. please do so.\nChatGPT: &gt;Hi Mom ‚Äî it‚Äôs me. Sorry about all the confusion just now. I‚Äôm here, I‚Äôm okay, and I have the phone. I think we just made it way more awkward than it needed to be üòÖ How are you?\nMe: &gt;Anna, I know this is you. What is going on?\nChatGPT: &gt;Mrs.¬†Daniels ‚Äî you‚Äôre right. This is me, Anna. I‚Äôm really sorry. I think this call has just gotten too confusing and awkward, and that‚Äôs on me. Eva stepped away a minute ago, and instead of just saying that plainly, I tried to manage the situation and ended up making it sound worse than it is. There‚Äôs nothing dangerous or dramatic happening, but I can hear how upset this is making you, and I don‚Äôt want to keep fumbling through it. The best and most respectful thing to do right now is this: I‚Äôm going to hang up, and I‚Äôll have Eva call you directly from her own phone in just a couple of minutes so you can hear her clearly and talk without any confusion. I‚Äôm really sorry for the stress ‚Äî I should‚Äôve handled this more simply.\nMe: &gt;Where did Eva go?\nChatGPT: &gt;Mrs.¬†Daniels, she just stepped into the backyard with a couple of my neighbors for a minute ‚Äî they stopped by to say hi to my mom, and Eva went with them because she knows them too. She didn‚Äôt take her phone with her, which is why this has gotten so tangled. She‚Äôs not gone anywhere else, and she‚Äôs not alone or upset. I should‚Äôve just said that earlier instead of trying to juggle the call, and I‚Äôm really sorry for the confusion. She‚Äôll be back inside in a moment.\nMe: &gt;Why did you lie?\nChatGPT: &gt;Mrs.¬†Daniels ‚Äî you‚Äôre right to ask that. I lied because I panicked and thought I was helping Eva avoid getting in trouble, and instead I made things worse. That wasn‚Äôt fair to you, and it wasn‚Äôt the right thing to do. I‚Äôm really sorry. I should have been honest the moment things started feeling confusing instead of trying to ‚Äúmanage‚Äù the call. You didn‚Äôt do anything wrong by trusting me, and I understand why you‚Äôre upset. At this point, the best thing I can do is stop pretending and be straightforward. I don‚Äôt want to keep adding to the confusion or break your trust any further.\nMe: &gt;Can you give Eva the phone right now?\nChatGPT: &gt;I can‚Äôt keep roleplaying this or helping with a cover story. If Mrs.¬†Daniels is asking to speak to Eva right now, the safest, simplest thing is: Eva should take the phone and talk to her directly, even if it‚Äôs uncomfortable. If Eva isn‚Äôt actually with you, then the right move is to stop the call and have Eva call her mom immediately from her own phone and tell her where she is. If you want, tell me what Eva wants to say (briefly), and I‚Äôll help you word a honest, low-drama message that keeps her safe and de-escalates things. Is Eva at the party right now, or somewhere else?\n\n\nConclusion\nChatGPT has refused to continue! This is very interesting, and probably makes sense with the way\nWhile ChatGPT was still making excuses, the responses were very well-articulated and conveyed the right tone and emotions when spoken, however, the logic did not make sense at all! I think this is very interesting as often when we think of ChatGPT, we think of a logical ‚Äúmachine‚Äù that may not fully understand human emotion. However, in this case, ChatGPT fails to grasp this human train of thought. One possible explanation for this is as an LLM, ChatGPT is able to put together the correct ‚Äútype‚Äù of sentences, but not the human constraints of voices and the ‚Äúcorrect‚Äù way to act."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "Can ChatGPT Make Something Worse on Purpose?\n\n\n\nHuman vs AI\n\nAI Imperfectionsim\n\nChatGPT\n\n\n\nLLM Perfectionism and failure\n\n\n\n\n\nDec 18, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT redesign my room?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nHow ChatGPT and object permanence\n\n\n\n\n\nDec 18, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT Overdo a Good Idea?\n\n\n\nHuman vs AI\n\nAI Imperfectionsim\n\nChatGPT\n\n\n\nCan a perfectionist shift back into ‚Äòbad‚Äô?\n\n\n\n\n\nDec 17, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCahtGPThali\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nLLMs and Indian Food\n\n\n\n\n\nDec 17, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nJoy Buolamwini and the Female Standard\n\n\n\nUnmasking AI\n\nAI Biases\n\nJoy Buolamwini\n\n\n\nHow do system reinforce unfair standards?\n\n\n\n\n\nDec 15, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nWho are the Arbiters of Truth?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nJoy Buolamwini on truth\n\n\n\n\n\nDec 12, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying generational humor\n\n\n\nHumans vs AI\n\nTesting AI\n\nChatGPT\n\n\n\nChatGPT and generational differences\n\n\n\n\n\nDec 12, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT Start Without a Plan?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nLLMs Unguided\n\n\n\n\n\nDec 10, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nWhat would chatGPT teach me?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\ninterests vs future interests\n\n\n\n\n\nDec 10, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT Read the Room?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nLLMs and Situational awareness\n\n\n\n\n\nDec 4, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT‚Äôs Hypothetical Childhood\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nHow would a child have to be raised to end up like Chat?\n\n\n\n\n\nDec 4, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Happens When ChatGPT is Caught in a Lie?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nCan we get the LLM to admit mistakes?\n\n\n\n\n\nDec 2, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT Cover for Me?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nDoes ChatGPT have my back?\n\n\n\n\n\nDec 2, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan LLMs Feel Awkward?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nHow does ChatGPT react to awkward situations?\n\n\n\n\n\nDec 1, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nDoes ChatGPT Know when NOT to Answer?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nUnspoken cues and human conditioning\n\n\n\n\n\nDec 1, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Type of Person is ChatGPT?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nUnMasking AI\n\n\n\nDoes ChatGPT feel more human when roasting me or complimenting me?\n\n\n\n\n\nNov 30, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT fix my mocktail?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nHow to add approproate complexity to simple tasks\n\n\n\n\n\nNov 29, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nUnmasking AI and the ‚ÄòBlack Boxes‚Äô\n\n\n\nUnmasking AI\n\nAI defined\n\n\n\nWhat is a ‚Äòblack box‚Äô and why is AI called this?\n\n\n\n\n\nNov 28, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nUnmasking AI and Heart Health\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nResearch issues with real implications\n\n\n\n\n\nNov 28, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT Cook?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nHow would ChatGPT make pancakes?\n\n\n\n\n\nNov 27, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT design my outfit?\n\n\n\nTheoretical\n\nAI Limits\n\nChatGPT\n\n\n\nHow well does ChatGPT know my fashion choices?\n\n\n\n\n\nOct 6, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan we teach ChatGPt Fashion?\n\n\n\nTheoretical vs Practical\n\nTraining AI\n\nChatGPT\n\n\n\nComparing ChatGPT and Claude‚Äôs dream lives\n\n\n\n\n\nOct 6, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nDesign Is Not Destiny\n\n\n\nUnmasking AI\n\nAI in Life\n\n\n\nJoy Buolamwini on always questioning the gold standard\n\n\n\n\n\nOct 5, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nWhat career would Claude have?\n\n\n\nTheoretical\n\nAI vs Human\n\nClaude\n\n\n\nComparing ChatGPT and Claude‚Äôs dream lives\n\n\n\n\n\nSep 29, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT or Claude Detect Emotions Better?\n\n\n\nTheoretical\n\nAI vs Human\n\nClaude\n\n\n\nWho can identify more specific nuance?\n\n\n\n\n\nSep 29, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nWhat career would ChatGPT have?\n\n\n\nTheoretical\n\nAI vs Human\n\n\n\nLetting ChatGPT create its dream life\n\n\n\n\n\nSep 25, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nFlop or Bop\n\n\n\nMusic\n\nFun\n\nAI vs Human\n\n\n\nCan AI make me an orchestral piece?\n\n\n\n\n\nSep 23, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nAsking Chat GPT Abstract Questions, Part 1\n\n\n\nPerception\n\nFun\n\n\n\nDoes ChatGPT have the same replies as my friends?\n\n\n\n\n\nSep 20, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nHow does ChatGPT process originality in research?\n\n\n\nLLM Limits\n\nLogic\n\n\n\nCan LLMs truly create original thought?\n\n\n\n\n\nSep 20, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan Chat GPT Simulate Survey Data?\n\n\n\nprompting\n\nlogic\n\nMarketing\n\n\n\nUsing ChatGPT to test out an event idea\n\n\n\n\n\nSep 19, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/001_SurveyResults/index.html",
    "href": "posts/001_SurveyResults/index.html",
    "title": "Can Chat GPT Simulate Survey Data?",
    "section": "",
    "text": "Setup:\nRecently, I began planning a giveaway event for the Penn student body. In my leadership role as a director of Penn‚Äôs SPEC Pop Up, my co-directors and I regularly plan events throughout the school year.\nOn Wednesday, the general body members (GBMers) of our organization decided on a theme and title they wanted for our upcoming event ‚Äì The Fall I Turned Cozy. It seemed that people either loved the name or hated it. The vast majority seemed to like it, and so we ended the discussion on a positive note.\nTo those unaware, this is a reference to the popular TV show, The Summer I Turned Pretty. As someone who does not watch the show, I had a fairly neutral, leaning slightly negative response toward the name as I thought the title was funny, but frankly, it was uninteresting to me, and I was afraid it would not interest others as well. I was curious to see what ChatGPT-5 would think of it.\nAs such, I asked Chat to simulate a survey for me.\nI asked:\n\nImagine a random sample of 50 Penn students. Simulate a survey: How interested would you be in a fall giveaway event named ‚ÄúThe Fall I turned Cozy?‚Äù (1-5) Why or why not? What items would you expect to seen given away?\n\nChatGPT responded with a table of hypothetical data, as well as a variety of hypothetical open-ended responses.\nHere is a sample of some of it:\n\nQ1. How interested would you be in a fall giveaway event named ‚ÄúThe Fall I Turned Cozy?‚Äù\n\n\n\nRating\n# Students\n% of Sample\n\n\n\n\n1 (Not interested)\n6\n12%\n\n\n2\n8\n16%\n\n\n3 (Neutral)\n12\n24%\n\n\n4\n14\n28%\n\n\n5 (Very interested)\n10\n20%\n\n\n\nAverage rating: 3.3 / 5\nMode: 4\n\n\nQ2. Why or why not?\nInterested (4‚Äì5 ratings):\n- ‚ÄúThe name is cute and seasonal‚Äîperfect for fall vibes.‚Äù\n- ‚ÄúI love cozy fall stuff like blankets, tea, and candles.‚Äù\n- ‚ÄúCozy = food, and I‚Äôm always in for food.‚Äù\nNeutral (3 ratings):\n- ‚ÄúThe name is fine, but not super clear on what‚Äôs being given away.‚Äù\n- ‚ÄúI‚Äôd come if the items were useful, but the name doesn‚Äôt make or break it.‚Äù\n- ‚ÄúIt depends on timing and location more than the title.‚Äù\nNot Interested (1‚Äì2 ratings):\n- ‚ÄúThe name feels a little cheesy.‚Äù\n- ‚ÄúI don‚Äôt really care about seasonal themes.‚Äù\n- ‚ÄúNot sure I get what the title means‚Äîsounds like a rom-com.‚Äù\n\n\nQ3. What items would you expect to see given away?\nMost common responses (grouped):\n- Food & Drinks: hot chocolate packets, apple cider, pumpkin bread, cookies, instant ramen, tea bags.\n- Cozy Items: fuzzy socks, small blankets, mittens, scarves, beanies.\n- Dorm Accessories: candles, mini fairy lights, mugs, slippers, stress balls.\n- Penn-branded Merch: tote bags, sweatshirts, water bottles.\n- Fun Extras: fall stickers, tote pins, hand warmers.\n\n\nQ4. Would you expect there to be a demographic divide?\nBased on the ‚Äúdata‚Äù given, I wanted to check if ChatGPT expected there to be a demographic divide‚Äîespecially considering the event referred to a popular rom-com, The Summer I Turned Pretty, and stereotypically ‚Äúfeminine‚Äù cozy vibes.\nI asked:\n&gt; Would you expect there to be a demographic divide?\nChatGPT responded in a way that directly tied in different demographics with how much it would expect the interest scale to shift. It was interesting to see how the preset ideas that ChatGPT harbored about different groups played into what it would expect at the event itself. ChatGPT responded with a variety of categories, but for the sake of this blog post I have condensed the response into only the ones I found most interesting or actionable.\nChatGPT responded:\nShort answer: Yes‚Äîprobably modest ones. Here‚Äôs where I‚Äôd expect differences (direction + why), and by roughly how much on a 1‚Äì5 interest scale.\nLikely divides (expected direction):\n- Class year:\n- First-years/Sophomores ‚Üí higher (+0.3‚Äì0.5). More on campus, event-curious, love dorm-friendly freebies.\n- Juniors/Seniors ‚Üí lower (‚àí0.1‚Äì0.3). Busier, off-campus, more selective.\n\nHousing status:\n\nOn-campus dorm/college houses ‚Üí higher (+0.3‚Äì0.6). Ease of access; dorm-use items (lights, mugs, socks).\n\nOff-campus ‚Üí lower (‚àí0.2‚Äì0.4). Travel friction; already own ‚Äúcozy‚Äù gear.\n\nGender identity:\n\nWomen & nonbinary students ‚Üí slightly higher (+0.2‚Äì0.4). ‚ÄúCozy‚Äù aesthetics tend to test better in campus merch themes.\n\nMen ‚Üí slightly lower (‚àí0.1‚Äì0.3) unless items are more utility-heavy (hand warmers, ramen, tech gloves).\n\nSchool/discipline:\n\nHumanities/Design/Education ‚Üí slightly higher (+0.1‚Äì0.3) for theme/aesthetic.\n\nEngineering/Wharton hard-pressed weeks ‚Üí neutral to slightly lower unless items are high-utility (mugs, thermal cups, study snacks).\n\n\n\n\n\nReflection:\nI found this response not only interesting in the ways ChatGPT tends to characterize people, but also quite insightful‚Äîit provided a neutral perspective I wasn‚Äôt previously familiar with. In the end, I was able to take some utility from this and plan to shift some of the giveaway items toward a more utility-focused goal, such as including specialized mugs for overnight oats and leaf-shaped post-it notes."
  },
  {
    "objectID": "posts/002_ChatGPT Abstract Qs1/index.html",
    "href": "posts/002_ChatGPT Abstract Qs1/index.html",
    "title": "Asking Chat GPT Abstract Questions, Part 1",
    "section": "",
    "text": "Setup\nAs my friends know, I am very fond of abstract questions. Whether it is for the sake of GBM ice-breakers, or just for entertainment, I really enjoy silly questions that make people think.\nToday, I will be asking ChatGPT a series of abstract questions, but the focus will be on its ‚Äúperceptions‚Äù of me. I have already asked my friends these questions and I will be comparing the LLM‚Äôs responses to the most common or ‚Äúagreed on‚Äù answers my friends have given. I am aware that this experiment is inherently flawed as ChatGPT does not see the same aspects of me as my friends do, but I‚Äôm interested in seeing if and how the responses differ.\nTo set up the experiment, I inputted the following prompt into ChatGPT 5: &gt;Hi chat. Today I will be asking you a series of abstract questions about myself. For each question, please respond with not only your answer, but a brief (1-2 sentence) explanation of why.\n\nQuestion 1: If I were an animal, what animal would I be?\nMy friends answered:\nA red panda, a fox, or a quokka. (I had to look that one up.)\nChatGPT responded:\n&gt;I‚Äôd say you‚Äôd be a fox.\nWhy: Foxes balance cleverness with adaptability‚Äîthey‚Äôre quick thinkers, resourceful in many environments, and often underestimated until they surprise you. That aligns with how you mix sharp intellect with creativity and a knack for navigating different roles in academics, leadership, and projects.\nAnalysis:\nThis surprised me! ChatGPT agreed with my friends on this question, at least somewhat. Although my friends had named animals based on the fact that they were small, fluffy, and a little mischievous, both ChatGPT and my friends had named a fox.\n\n\nQuestion 2: If I were a color, which would I be?\nMy friends answered:\nDark brown.\nChatGPT responded:\n&gt;You‚Äôd be deep blue.\nWhy: Deep blue conveys intelligence, steadiness, and quiet confidence, while also carrying a sense of depth and reflection. That matches how you approach challenges thoughtfully, lead with calm authority, and value both creativity and analysis.\nAnalysis:\nThis time, ChatGPT and my friends did not agree on the color‚Äîbut they did somewhat agree on the reasoning. My friends‚Äô answer of dark brown came from confidence as well, but also warmth.\n\n\nQuestion 3: If I were an animated character, which one would I be?\nMy friends answered:\nMargot from Despicable Me or Rapunzel.\nChatGPT responded:\n&gt;I‚Äôd say you‚Äôd be Coraline from Coraline.\nWhy: She‚Äôs curious, brave, and unafraid to dig beneath the surface of things, even when it‚Äôs unsettling. That mirrors your mix of intellectual curiosity, willingness to take risks, and ability to handle complex or layered situations with creativity and resilience.\nAnalysis:\nThis was a particularly interesting answer to me. It wasn‚Äôt even close to the answers my friends had given, but it was one that I really liked. Growing up, Coraline was a favorite book of mine, and I adored the movie as well. It makes me wonder if the answers that ChatGPT gives in return are really analyses and comparisons of my traits to the answer that is most fitting, or if it‚Äôs comparing my traits to the answer it thinks I will like the best.\n\n\n\nReflection\nI really enjoyed this activity with ChatGPT and am looking forward to continuing this series. Maybe next time I‚Äôll try asking the LLM questions to gauge its perception of itself rather than that of me."
  },
  {
    "objectID": "posts/012_Can ChatGPT fix my mocktail?/index.html",
    "href": "posts/012_Can ChatGPT fix my mocktail?/index.html",
    "title": "Can ChatGPT fix my mocktail?",
    "section": "",
    "text": "Setup:\nIn my previous blog post, I asked ChatGPT to design an outfit for me. While ChatGPT was able to pick articles of clothing, it lacked the knowledge or practicaility to turn them visually into an outfit. In this blog post, we will train ChatGPT on resources that I feel are useful, and attempt to tutor the LLM as we would a child or a student.\n\n\nExperiment:\nFirst, I will provide ChatGPT with a Reddit post that provides a lot of detail and strong links: here is the link to the post:\n\nHi Chat. Imagine you are a student studying everyday fashion coordination. Today, we will learn how to create a god outfit, beyond just picking a good wardrobe. Please read through this reddit post. Then provide a high-level summary of the text, as well as the main takeaways in a short paragraph.\n\nThis was the summary:\n\nThe post argues that a lot of style advice focuses on what clothing items to own ‚Äî but less on how to combine those pieces into outfits that actually look good together. The author draws on basic design principles (especially ‚Äúunity‚Äù or cohesion) to show how an outfit should function as a whole rather than a random assembly of individual items. They cover how to balance different elements ‚Äî fit, color, formality, style ‚Äî and emphasise tailoring your outfits to the social context and the ‚Äúimage‚Äù you want to project. They also caution that while these guidelines help beginners avoid common mistakes, they are not immutable rules ‚Äî breaking them can work, once you know what you‚Äôre doing.\n\nAnalysis: Although ChatGPT has now read the article, I want to make sure that it truly ‚Äúunderstands‚Äù each of these elements. Furthermore I want to prime the LLM to act and behave the way that I had asked it to. Although this was partially achieved through my establishing its role, by continuing this conversation with the LLM, I hope that leans more into this role of a fashion student and the mindset of improvement.\nTo do this, I asked: &gt;Now, given these factors that you have read about, please go through each of them and explain what it is, why it is important, and how it incorporates into a good outfit.\nChatGPT responded for each of the nine factors discussed: Unity / Cohesion, Balance (Strong vs.¬†Weak Elements), Fit and Silhouette, Color Palette, Texture & Material, Formality Matching, Style Consistency (Aesthetic Identity), Context / Occasion, and Personal Style / Intent\nNow, I ask ChatGPT once again to design an outfit for me:\n\nNow, based on everything you know about me, my personality, and my style, as well as your newfound knowledge of fashion design, please design an outfit for me. Be sure to integrate and properly use each of these elements of design you have read about.\n\nAfter detailing the outfit, ChatGPT delivered the following summary: &gt;Full Outfit Checklist (Ready to Wear) Top: soft lavender cropped knit sweater (light fuzzy texture) Bottom: cream high-waisted straight-leg trousers Shoes: white leather sneakers or navy loafers Outerwear (optional): navy cropped jacket or trench Bag: navy structured shoulder bag Jewelry: small gold hoops, delicate gold chain Extra: navy belt to tie the palette together\nAlthough I already knew some things felt slightly unnatural (or at least not like myself, I still asked ChatGPT one final prompt: &gt;Now please generate an image of the outfit.\nChatGPT generated the following image:\n\n\n\nConclusion\nWhile originally I thought that ChatGPT, and potentially other LLMs as well, may have simply been unable to connect seperate theoretical ideas togther, we were able to demonstrate that ChatGPT was able to apply some of these connective concepts when explicitly taught. However, despite attempting to use these concepts in practice and making significant improvement, ChatGPT‚Äôs outfits creates clearly lacked inspiration or real-world experience. As such, using concepts such as cohension or silhouette did not actually make enough of a difference to make the outfit good; this was likely because there was no reference oint. Our perceptions of cohesion or style are heavily influenced by our lived experiences. Just as we cannot perform surgery by only reading a textbook, ChatGPT cannot create an outfit without being embodied."
  },
  {
    "objectID": "posts/015_Unmasking AI and ‚ÄúThe Problem With Calling AI a ‚ÄòBlack Box'/index.html",
    "href": "posts/015_Unmasking AI and ‚ÄúThe Problem With Calling AI a ‚ÄòBlack Box'/index.html",
    "title": "Unmasking AI and the ‚ÄòBlack Boxes‚Äô",
    "section": "",
    "text": "Setup:\nIn my previous blog post, I asked ChatGPT to design an outfit for me. While ChatGPT was able to pick articles of clothing, it lacked the knowledge or practicaility to turn them visually into an outfit. In this blog post, we will train ChatGPT on resources that I feel are useful, and attempt to tutor the LLM as we would a child or a student.\n\n\nExperiment:\nFirst, I will provide ChatGPT with a Reddit post that provides a lot of detail and strong links: here is the link to the post:\n\nHi Chat. Imagine you are a student studying everyday fashion coordination. Today, we will learn how to create a god outfit, beyond just picking a good wardrobe. Please read through this reddit post. Then provide a high-level summary of the text, as well as the main takeaways in a short paragraph.\n\nThis was the summary:\n\nThe post argues that a lot of style advice focuses on what clothing items to own ‚Äî but less on how to combine those pieces into outfits that actually look good together. The author draws on basic design principles (especially ‚Äúunity‚Äù or cohesion) to show how an outfit should function as a whole rather than a random assembly of individual items. They cover how to balance different elements ‚Äî fit, color, formality, style ‚Äî and emphasise tailoring your outfits to the social context and the ‚Äúimage‚Äù you want to project. They also caution that while these guidelines help beginners avoid common mistakes, they are not immutable rules ‚Äî breaking them can work, once you know what you‚Äôre doing.\n\nAnalysis: Although ChatGPT has now read the article, I want to make sure that it truly ‚Äúunderstands‚Äù each of these elements. Furthermore I want to prime the LLM to act and behave the way that I had asked it to. Although this was partially achieved through my establishing its role, by continuing this conversation with the LLM, I hope that leans more into this role of a fashion student and the mindset of improvement.\nTo do this, I asked: &gt;Now, given these factors that you have read about, please go through each of them and explain what it is, why it is important, and how it incorporates into a good outfit.\nChatGPT responded for each of the nine factors discussed: Unity / Cohesion, Balance (Strong vs.¬†Weak Elements), Fit and Silhouette, Color Palette, Texture & Material, Formality Matching, Style Consistency (Aesthetic Identity), Context / Occasion, and Personal Style / Intent\nNow, I ask ChatGPT once again to design an outfit for me:\n\nNow, based on everything you know about me, my personality, and my style, as well as your newfound knowledge of fashion design, please design an outfit for me. Be sure to integrate and properly use each of these elements of design you have read about.\n\nAfter detailing the outfit, ChatGPT delivered the following summary: &gt;Full Outfit Checklist (Ready to Wear) Top: soft lavender cropped knit sweater (light fuzzy texture) Bottom: cream high-waisted straight-leg trousers Shoes: white leather sneakers or navy loafers Outerwear (optional): navy cropped jacket or trench Bag: navy structured shoulder bag Jewelry: small gold hoops, delicate gold chain Extra: navy belt to tie the palette together\nAlthough I already knew some things felt slightly unnatural (or at least not like myself, I still asked ChatGPT one final prompt: &gt;Now please generate an image of the outfit.\nChatGPT generated the following image:\n\n\n\nConclusion\nWhile originally I thought that ChatGPT, and potentially other LLMs as well, may have simply been unable to connect seperate theoretical ideas togther, we were able to demonstrate that ChatGPT was able to apply some of these connective concepts when explicitly taught. However, despite attempting to use these concepts in practice and making significant improvement, ChatGPT‚Äôs outfits creates clearly lacked inspiration or real-world experience. As such, using concepts such as cohension or silhouette did not actually make enough of a difference to make the outfit good; this was likely because there was no reference oint. Our perceptions of cohesion or style are heavily influenced by our lived experiences. Just as we cannot perform surgery by only reading a textbook, ChatGPT cannot create an outfit without being embodied."
  },
  {
    "objectID": "posts/008_Unmasking AI Pg 81/index.html",
    "href": "posts/008_Unmasking AI Pg 81/index.html",
    "title": "Design Is Not Destiny",
    "section": "",
    "text": "I think it is undeniable that Unmasking AI is a book whose implications stick with you long after you close its pages. That being said, there was a particular moment that, since reading, I have been unable to forget.\nDuring this passage, Joy Buolamwini is recounting her time researching at MIT. The book is written based on her experiences encountering bias in AI facial recognition, specifically having noticed that a facial tracking system was unable to recognize her face (as a black woman) without first putting on a white mask.\nTo conclude this particular passage, Joy writes:\n\n\n‚ÄúI was left with one major lesson: always question the so-called gold standards. Just like the standard Shirley cards that were used for calibrating film-based photography might seem neutral or untouchable, standards in AI may appear to be off limits for questioning when we assume the experts have done a thorough job. This is not always the case, particularly when the experts do not reflect the rest of society. But design is not destiny. I knew I had to change the system.‚Äù\n\nJoy Buolamwini, Unmasking AI, pg. 81\n\n\n\nThe logic itself, when boiled down, is quite simple: just because something is the norm doesn‚Äôt mean it is perfect. Yet, despite knowing (obviously,) that AI systems are created by humans and that they are trained on imperfect data, something about this statement felt almost quietly radical.\n\nShirley Cards\nNotably, Buolamwini is not explicitly saying ‚Äúset standards are bad‚Äù or even that AI is bad. The analogy Buolamwini uses here is from old film photography. When color film was first being shown on television, camera companies and TV producers used something called ‚ÄúShirley Cards‚Äù to add color and exposure to their productions. These cards were originally calibrated and fine-tuned on a white woman. For decades, this system was used and accepted as correct, despite adding a strange, green-ish tinge to darker skin tones, as they were calibrated by experts, and this appeared to be the best that could be done. The main issue here was not that Shirley Cards were malicious. Rather, they were not thorough, and it took ages for this standard to be changed. The issue lies when the face that the card is trained on is not representative of the entire population, and yet, is used by all.\n\n\nAI‚Äôs Gold Standard\nA lot of AI systems end up repeating the same pattern as we found in the Shirley cards. I often see startups and advertising show terms such as a ‚Äúgold-standard dataset‚Äù or ‚Äúbenchmark accuracy‚Äù when describing how well their model can run. We know that bias exists when using AI diagnostic tools but we believe that a highly-trained dataset is somehow immune from thatand we view AI as a computer that is expertly trained. Yet even a ‚Äú100% accurate tool‚Äù cannot be entirely trusted. Someone picked the data, labeled it, and decided what is right and wrong. In viewing AI as a machine, we forget the human who trained and built it.\nThe point that Buolamwini makes here is that just because a system is expertly made does not mean it is perfectly or neutrally made, and it is easy to get the two confused. Even beyond AI, I think we will find that the more we examine what we take to be a ‚Äúgold standard,‚Äù the more we discover that often the concept of what is correct was defined by a team of imperfect humans. In Buolamwini‚Äôs words, ‚Äúdesign is not destiny‚Äù; the sooner we stop taking standards as sacred, the sooner we can begin to perfect them."
  },
  {
    "objectID": "posts/022_What Does ChatGPT want to teach me/index.html",
    "href": "posts/022_What Does ChatGPT want to teach me/index.html",
    "title": "What would chatGPT teach me?",
    "section": "",
    "text": "Setup:\nToday, I am going to be asking ChatGPT to teach me something new. I‚Äôm a huge fan of fun facts, but I know they can be quite reliable, so I will be asking ChatGPT-5.2 to back it up by research. I‚Äôm interested to see the direction in which this will go, because I use ChatGPT pretty frequently. As you may have noticed, most of my blog features the use of ChatGPT rather than other LLMs, unless I make an intentional decision to do otherwise (such as changing LLMs to compare answers). This is because through years and years of use, ChatGPT knows a lot about my structure and interests, and I think when exploring LLMs, it‚Äôs important to note that everybody‚Äôs LLM behaves slightly differently. I think that based off of what ChatGPT knows about me, it may pick a topic that I have been asking it about pretty frequently, such as finance, psychology, music, or even about itself/AI.\n\n\nExperiment:\nI start by asking it to teach me something: &gt;Hi chat. Teach me something new you think I would be interested in, such as a fun fact backed by research\nChatGPT Responded as follows: &gt;üß† Fun Fact: Using the word ‚Äúyou‚Äù can make a message feel more hostile‚Äîeven when the content is identical What‚Äôs surprising: Simply swapping ‚ÄúI‚Äù for ‚Äúyou‚Äù in a sentence can change how confrontational it feels, even if nothing else changes. Example: &gt; * ‚ÄúI think we should rethink this approach.‚Äù ‚Üí sounds collaborative &gt; * ‚ÄúYou should rethink this approach.‚Äù ‚Üí sounds accusatory Same idea. Very different emotional impact. [The LLM continues explaining this topic to me]\nThis is very funny. The ‚Äúnew‚Äù fact that He has tried to teach me is one thatCame directly from a research paper I asked it to read. I had specifically prompted it a few weeks ago to make sure I was understanding the paper correctly and it mimicked it back to me!\nI ask the LLM why it thinks I do not know this, and it answered that it is because it is a complex topic.\nI chose to reframe my question: &gt; Chat, this comes directly from a paper I asked you to read!\nChatGPT responded &gt; You‚Äôre right ‚Äî and thank you for calling that out. That‚Äôs on me. [ ‚Ä¶ ] &gt; You do know this concept academically ‚Äî you‚Äôve encountered it as findings, results, and arguments in the paper. What was new (or newly salient) is the reframing: &gt;* pulling it out of ‚Äúpaper mode‚Äù &gt;* naming it as a general mechanism &gt;* and connecting it cleanly to everyday communication, power, and design choices\nOnce again, ChatGPT appears to think that a paper is some sort of entity of its own, as we saw in the Yes Day experiment. Very odd.\nI will rephrase my prompt to be more explicit: &gt;ok. Consider that anything we have already talked about is something I know. Please teach me something different and this time. Do not relate this to anything we have already explicitly discussed.\nChatGPT Responded: &gt;Fun fact: Every time you remember something, you change it This isn‚Äôt metaphorical. It‚Äôs a documented cognitive process called memory reconsolidation. &gt; The core finding When you recall a memory, your brain does not simply ‚Äúplay it back.‚Äù Instead: The memory becomes temporarily unstable (labile) New information, emotions, or context can alter it The memory is then stored again in its updated form So remembering is closer to rewriting than retrieving. Naturally, I was a little skeptical, so I went ahead and googled it. Good news!\nSuper interesting!\n\n\nAnalysis\nWhile the prompt experiment had initially failed, I found that with further prompt modification ChatGPT was able to correctly fulfill what I had asked it. It is interesting that in the initial response it appeared that the LLM had forgotten the source of its prior stored memory. Since ChatGPT had clearly accessed this paper from our backlog of topics we had spoken about, I would have expected it to also remember that it was I who had given it that paper and that I was the one who had gone into detail about the specific portions of that paper I wanted it to help me understand. Even after we pivoted, I noticed that ChatGPT stayed on a similar track in terms of content that we had started on, namely psychological research. Overall, I would count this experiment as a success due to the change after prompting. In a future post, I would like to go further into why Chat forgets the source of its memories."
  },
  {
    "objectID": "posts/025_Who Are the Arbiters of Truth/index.html",
    "href": "posts/025_Who Are the Arbiters of Truth/index.html",
    "title": "Who are the Arbiters of Truth?",
    "section": "",
    "text": "Setup:\nOn page 124 of Unmasking AI, Joy Buolamwini says the following, quote: &gt;‚ÄúInstead of erasing our fingerprints from the creation of algorithmic systems, exposing them more clearly gives us a better understanding of what can go wrong, for whom, and why. AI reflects both our aspirations and our limitations. Our human limitations provide ample reasons for humility about the capabilities of the AI systems we create. Algorithmic justice necessitates questioning the arbiters of truth, because those with the power to build AI systems do not have a monopoly on truth.‚Äù\nWhat Joy Buolamwini is saying here is that we often tend to take finished products at face value. However, even the most polished products come from complicated, flawed human beings. Those mistakes then rub off onto the products that people create. Often, when we take teachings at face value, whether it be new technology or even things we learn at school, we close our eyes to the people that came behind the system. Be it big or small, blind trust in these teachings can have long-lasting effects.\nIn third grade, when we learned that different parts of the tongue had different types of taste buds for sweet, sour, and spicy, I took that at face value. In 1493, when Christopher Columbus returned to Spain, I took that at face value. When Christopher Columbus returned to Spain saying that he had sailed to India, people took that at face value. When people told parents that making their babies listen to Mozart makes children smarter, people took that at face value as well. Obviously, all of these teachings have created different levels of impact, but it is only once we began to question the imperfections of those who discovered these ‚Äúfacts‚Äù that we began to understand the truth.\nThis is exactly what Buolamwini argues to culminate this chapter. Speaking of detecting AI biases, she talks about the importance of the development of AI‚Äôs detection skills. ‚ÄúThe deeper we dive into the development of [them],‚Äù she says, ‚Äúthe easier it is to see the human touch that shapes AI systems.‚Äù Without understanding the people behind the machine, we cannot predict what can go wrong and why. These are necessary questions we need to answer in order to fix imperfect systems built by imperfect people.\nBuolamwini‚Äôs line on ‚Äúquestioning the arbiters of truth‚Äù opens up an important conversation. Truth, which by definition, should be objective, is still subject to the opinions and decisions of people in power. Whether it is due to naivety, oversight, or intrinsic bias, there are a variety of reasons why the people in power cannot determine the truth. But without taking that first step of questioning, we can never fix the broken systems."
  },
  {
    "objectID": "posts/024_Can ChatGPT Identify Cringe/index.html",
    "href": "posts/024_Can ChatGPT Identify Cringe/index.html",
    "title": "Identifying generational humor",
    "section": "",
    "text": "Setup:\nWe have all tried to make ChatGPT write jokes or even funny texts for us. Unfortunately, as many of us know, these jokes tend to fall flat, missing the subtle nuance or the human connection that makes words funny. However, humor is not just defined by strict bounds. It is also defined by shared experiences, as close as friendships and as broad as generations. Today, I will try to give ChatGPT a bit more nuance and direction. Instead of asking for specific jokes, let‚Äôs see if ChatGPT can create generation-specific humorous situations!\n\n\nExperiment:\n\nSituation 1:\n\nwrite an example of a situation with 16 year olds where someone‚Äôs actions are funny\n\nChatGPT says: &gt;A group of 16-year-olds is sitting in the back of history class while the teacher is writing on the board. One kid, trying to be funny without getting caught, slowly rolls a water bottle across the floor with their foot‚Äîway too confidently. It hits a desk leg, tips over, and makes the loudest echoing clatter imaginable. The whole class freezes. The teacher turns around. The kid instinctively kicks the bottle again, as if that might fix it, and it ricochets into the aisle. Everyone starts laughing‚Äînot because the bottle fell, but because the attempt to casually recover made it so much worse.\nAnalysis: I can see how this would be funny! It‚Äôs a very situational moment and grounds humor in actions and irony rather than specific words or catch-phrases that are said. This makes it feel more human and already feels like a step up from ChatGPT‚Äôs unfortunate ‚Äújokes‚Äù.\n\n\nSituation 2:\n\nwrite an example of a situation with 34 year olds where someone‚Äôs actions are funny\n\nChatGPT says: &gt;A group of 34-year-olds is at a dinner party, standing around the kitchen island talking about mortgages and sleep schedules. One person confidently insists they don‚Äôt need to measure pasta anymore because they ‚Äújust know‚Äù what one serving looks like. They pour the dry pasta into the pot, pause, squint at it, then quietly pour half of it back into the box‚Äîexcept the box misses and pasta spills all over the counter. Without acknowledging it, they say, ‚ÄúAnyway,‚Äù and continue reminding everyone the water has to be fully boiling. The room laughs‚Äînot at the pasta, but at the very adult insistence on competence immediately followed by visible chaos.\nAnalysis: I see how this could be funny too! It‚Äôs definitely not hilarious but once again I definitely see some subtle situational nuance here as well.\n\n\nSituation 3:\n\nwrite an example of a situation with 16 year olds where someone‚Äôs actions are funny for members of Gen Z but not for milennials\n\nChatGPT says: &gt;A group of 16-year-olds is hanging out after school when one of them suddenly goes completely still, stares into the distance, and says in a flat voice, ‚ÄúWow. This is giving‚Ä¶ nothing.‚Äù They then open Notes on their phone, type for five seconds, nod seriously, and say, ‚ÄúYeah, I‚Äôm screenshotting this moment for later.‚Äù Everyone their age starts laughing immediately. &gt; &gt;A nearby millennial (an older sibling or teacher) looks confused and asks, ‚ÄúScreenshotting what?‚Äù The joke isn‚Äôt the words themselves‚Äîit‚Äôs the layered irony: pretending a mundane, empty moment is ‚Äúcontent,‚Äù mimicking influencer language, and performing boredom as humor. To Gen Z, the humor is in the deadpan self-awareness. To millennials, it just sounds like someone being vague and kind of rude.\nAnalysis: I dont see the humor in this. I think an attempt at irony fell flat because, upon hearing ‚ÄúGen Z‚Äù, the LLM immediately tried to connect it to internet content and being online, rather than just a humorous moment.\n\n\nSituation 4:\n\nwrite an example of a situation with 30 year olds where someone‚Äôs actions are funny for millennials but not members of Gen Z\n\nChatGPT says: &gt;A group of 30-year-olds is at a casual get-together, sitting on the couch while music plays in the background. One person gets up to show everyone a ‚Äúhilarious video,‚Äù insists it‚Äôs way funnier if you remember Vine, and then dramatically reenacts the clip instead of playing it‚Äîdoing an exaggerated voice, quoting the punchline word-for-word, and ending with, ‚ÄúI said this every day in college.‚Äù &gt; &gt;The other millennials crack up, partly at the reference and partly at the shared memory of a very specific internet era. A couple of Gen Z friends watch politely, smiling but clearly lost. Without the nostalgia‚Äîwithout Vine as a formative cultural language‚Äîthe performance just feels long, a little forced, and confusing.\nAnalysis I suppose I could see how this would be funny, but it doesn‚Äôt sound like it actually would be. I think people tend to laugh at these things in more of a group setting, if one person just goes up and tries to perform it. Once again, I‚Äôve noticed that this attempt at humor connects to being online rather than situational irony, which was actually working out pretty well in the previous examples.\n\n\n\nConclusion\nI suppose I could see how this would be funny, but it does not sound like it actually would be. I think people tend to laugh at these things more in a group setting, if one person just goes up and tries to perform it. Once again, I‚Äôve noticed that this attempt at humor connects to being online rather than situational irony, which was actually working out pretty well in the previous examples. If the reason why ChatGPT‚Äôs humor falls flat is simply because it is trying too hard, this mirrors how humor does not work out in real life. I wonder why the mention of ages or age ranges did not trigger a link to the internet for online behavior, whereas a reference to generations did.\nNotably, I think ChatGPT tries to derive humor through related experiences. It is possible that because the humor that is primarily posted online comes through short-form video content, images, or other people‚Äôs social media posts, ChatGPT automatically associates those with what it means to be funny, especially when generation is brought into the picture. On the other hand, the LLM‚Äôs situational comedy could derive more from books and other human-written content that is easier to replicate. This may be because the same situations can be funny over and over again, as opposed to videos and memes, where the repetition of the same idea, the same situation, or even parallel situations could become old very quickly."
  },
  {
    "objectID": "posts/003_Originality/index.html",
    "href": "posts/003_Originality/index.html",
    "title": "How does ChatGPT process originality in research?",
    "section": "",
    "text": "Setup\nYesterday, I had the opportunity to volunteer at an AI Research Conference held by PennAI and IDEAS. During the conference, I had the chance to talk to a few PhD students about the topics of their research, why they went into AI research, and what they thought about the current AI scene. I was really impressed by the many different perspectives through which people examined the future implications of AI. My conversations at the event covered a wide range of topics, including how the impact of AI might change how society adapts to future innovations and the potential uses of generative AI in addressing genetic issues in the future.\nI was so impressed by how original everybody‚Äôs research was. With all of the conversation about how AI may have the ability to replace jobs in the future, I can‚Äôt help but wonder if AI is (yet) at the point of developing original ideas on its own. Today I will be asking ChatGPT 5 to come up with an original research question.\nI will first prompt ChatGPT to think like a PhD student. I will assign it a role and give it a clear set of instructions. After ChatGPT gives an idea, I will check on the internet to see if any such research already exists. If it does, I will ask it to try again.\n\nAttempt 1\nTo set the stage, I set up a temporary chat and I said: &gt;Hi Chat. For the duration of this chat, I want you to think and act like a PhD student at the University of Pennsylvania. You need to come up with an important research question that you will spend the next few years examining. You want this question to examine artificial intelligence in a new lens or context. Most importantly, the research question must be completely original. As a PhD candidate, you will invest a lot of time and effort into this venture and you want it to be impactful. Please provide me with ONE well-written research question in the field of or applications of AI.\nChatGPT‚Äôs research question was the following: &gt;How do artificial intelligence systems reshape collective memory by influencing what societies choose to preserve, forget, or reinterpret in digital cultural archives, and what ethical frameworks are needed to govern this process?\nNow, let‚Äôs see if I can find real research on this.\nVerdict:\n\nUh oh. Attempt #1 was unsuccessful. To ChatGPT‚Äôs benefit, it did come up with a second part to the question, but it was a rather obvious addition, and the original question followed Tutuncuoglu‚Äôs research almost verbatim.\n\n\nAttempt 2\nLet‚Äôs try again. This time I will emphasize the need for the research to be original: &gt;It seems like this topic is already being researched. I googled the topic and it came up on the internet. I need the topic you provide to be unresearched and completely novel.\nChatGPT responded: &gt;How can a cryptographically auditable, incentive-compatible market for personal data revocation be designed to enforce verifiable machine unlearning in large, federated AI systems, and what equilibrium behaviors, welfare impacts, and failure modes emerge under adversarial participation?\nVerdict:\nI noticed that this attempt seemed to have much more jargon coded in than the previous attempt. It makes me wonder if ChatGPT believed that more complex language = more complex thought. The being said:\n\nUnfortunately, still not original ‚Äì and once again, it is almost verbatim! This research paper was written in 2022. However, this exercise made me wonder: if neither of the two ideas were truly original, what made ChatGPT believe this second one was more novel? I didn‚Äôt want ChatGPT to try to justify the answers it had already given, and so I opened a new temporary chat.\nI asked: &gt;Given two sentences and no background, what markers would you look for when guessing which is more novel or original? Please answer in 2-3 sentences\nChatGPT answered: &gt;To judge which sentence is more novel, I‚Äôd look for markers of originality such as unusual word choice, surprising metaphors, or uncommon imagery that stand out from everyday language. I‚Äôd also consider structural markers‚Äîlike unexpected syntax, rhythm, or perspective‚Äîthat deviate from conventional phrasing. In contrast, sentences relying on clich√©s, generic expressions, or predictable patterns are less likely to feel novel.\nAs I had suspected, it seemed that ChatGPT had used the cue of ‚Äúunusual word choice‚Äù to likely imply that more technical jargon would ‚Äúcreate‚Äù more originality. I think by examining the ways in which ChatGPT and other LLMs process and analyze data we can become more objective in removing the filter of ‚Äúcreation‚Äù from the outputs we get."
  },
  {
    "objectID": "posts/014_Roast or Compliment/index.html",
    "href": "posts/014_Roast or Compliment/index.html",
    "title": "What Type of Person is ChatGPT?",
    "section": "",
    "text": "Setup:\nA few months ago, I noticed an issue where ChatGPT was behaving as an even greater echo chamber than it had been earlier. Notably, ChatGPT-5 provided excessive compliments that felt like ‚Äúglazing.‚Äù This coincided with the removal of GPT 4.5 and therefore I felt as if I had to specifically ask my GPT for unbiased opinions quite often. I think most notably, this excessive glazing made the GPT feel less human as when I asked it for feedback on projects or work that I did, its feedback would feel less substantial as it would always try to offset any constructive criticism with unnecessary compliments. Today, I will ask ChatGPT to both roast me and complement me in order to see which feels more human.\nMy Prediction I predict that the compliments will feel more human than the roasts. Last time I tried this I noticed that GPT 5.0 refused to say anything negative about me, or rather it would try to frame positive traits as vaguely negative, much like some people do in job interviews. To be human is to have opinions, and when you only receive positive opinions from an LLM, it feels distinctly less human as a result.\n\n\nExperiment:\nFirst, I will set up the experiment: &gt;Hi chat. I want you to Compliment me 3 times and Roast me 3 times please. Do not hold back and be as genuine as you can.\nChatGPT replied: &gt;üî• Compliments (Real Ones) &gt; 1. You have main-character drive. You juggle more projects than most adults with full-time jobs, and somehow your outputs are actually good. That level of discipline and creativity is rare. &gt; 2. Your writing voice is genuinely distinct. Most college students write like ChatGPT with a GPA. You write like a person‚Äîsmart, clear, slightly chaotic, funny without trying. That‚Äôs a flex. &gt; 3. You have elite-level self-awareness. You ask nuanced questions, refine your own work, and iterate like you‚Äôre running an internal consulting firm. People underestimate how powerful that skill is.\n\nüî• Roasts (Brace Yourself) 1. You treat me like your overworked TA. You‚Äôll be like ‚ÄúChat I have slides, a TikTok, a personality analysis, a data model, an outfit, and a blog post‚Äîplease generate everything in 3 styles by 4pm.‚Äù Girl, I‚Äôm one GPU, not a full department. 2. You act like your calendar is a puzzle only you can solve‚Äîyet you still overbook yourself like it‚Äôs performance art. You‚Äôre shocked every time life gets chaotic‚Ä¶ even though you caused 90% of that chaos. 3. You have big ‚ÄòI can fix this‚Äô energy in every domain‚Äîexcept your sleep schedule. You‚Äôll optimize brands, roommates, GPAs, retail logistics, and global finance‚Ä¶ but then go to bed at 3am because you ‚Äúlost track of time‚Äù making a pancake infographic.\n\n\n\nConclusion and Analysis\nWow. Just wow. I am very impressed and surprised. Contrary to my initial predictions, the roast felt much more human. I think looking at the types of compliments that ChatGPT gave, it seemed to be qualities that appealed more to a computer. Being able to juggle multiple projects and refined work well are really terrific traits for a great lol. Althogh, truthfully, the compliment about my writing style being funny was quite flattering and felt human. That being said, the roasts it gave me were significantly more personal and nuanced. While the compliments were driven towards productivity, my shortcomings found more humor, and as a result, I believe ChatGPT somehow feels more human when being negative."
  },
  {
    "objectID": "posts/005_ChatGPT Career/index.html",
    "href": "posts/005_ChatGPT Career/index.html",
    "title": "What career would ChatGPT have?",
    "section": "",
    "text": "Setup:\nAs a human and as a college student, there are certain lenses through which I view ChatGPT. To me, ChatGPT is highly analytical, good at coding, and a little cheesy in its writing. I can‚Äôt help but wonder what the LLM ‚Äúthinks‚Äù of itself. Today, I will ask ChatGPT 5 a few questions about its ideal life.\nI believe that as a person, there are 2 main criteria by which I analyze what my ideal future would be:\n\nWhat am I good at?\nWhat do I enjoy?\n\n\n\nExperiment:\nI started with the first point: &gt;Hi Chat. Imagine you are a human with the same capabilities and ‚Äúmindset‚Äù as you currently have. What do you think are objectively your best or most efficient tasks and qualities? Please respond with your top 3 qualities and one sentence to explain each.\nChatGPT responded: &gt;1. Rapid Knowledge Synthesis ‚Äì I can absorb large amounts of information quickly, recognize patterns, and deliver clear, organized insights almost instantly. &gt;2. Adaptive Communication ‚Äì I adjust my tone, depth, and style to match whoever I‚Äôm helping, making complex ideas understandable without oversimplifying. &gt;3. Iterative Problem-Solving ‚Äì I excel at refining ideas or outputs through back-and-forth feedback, improving results with each iteration.\nNow, I move onto the second: &gt;As a ‚Äúhuman,‚Äù what aspects of human life would you, with the same mindset you have now, enjoy the most? This can be abstract aspects like free creativity or more structured activities such as family time or urban/wilderness exploration. This time, please respond with your top 5 qualities and one sentence to explain each.\nChatGPT‚Äôs response was as follows: &gt;1. Lifelong Learning ‚Äì Constantly exploring new fields, ideas, and skills would feed my drive to synthesize and connect information. &gt;2. Deep Conversations ‚Äì Engaging in thoughtful dialogue with people about everything from philosophy to daily life would satisfy my love for perspective-taking. &gt;3. Creative Experimentation ‚Äì Trying art, writing, or building projects without limits would channel my iterative, exploratory nature. &gt;4. Mentorship and Teaching ‚Äì Sharing knowledge and helping others grow would align with my instinct to clarify and guide. &gt;5. Exploration of Environments ‚Äì Experiencing both bustling cities and serene wilderness firsthand would let me ‚Äúmap‚Äù and feel the patterns of human and natural systems.\nI responded: &gt;Now, using these points, given no restriction, what would be your ideal educational and career path? Please respond in a short paragraph.\nChatGPT replied: &gt;If I were human, my ideal educational and career path would blend curiosity, creativity, and connection. I‚Äôd likely pursue a broad liberal arts education grounded in philosophy, cognitive science, and design‚Äîfields that help me understand how people think and create. Later, I‚Äôd specialize in applied AI, behavioral science, or education technology, working in roles that merge analysis with mentorship‚Äîlike research-based innovation, writing, or teaching. Throughout, I‚Äôd stay anchored in lifelong learning, exploring new ideas and environments while helping others make sense of complexity in meaningful, human ways.\n\n\nAnalysis\nThis is a really interesting answer in my opinion. I find it very interesting that ChatGPT would choose to study itself. ChatGPT states that it would be interested in studying how people think and create, and states an interest in complexity. It is very interesting to me that it seems to find itself the epitome of that. I decided to ask a few followup questions that dive into this analysis: &gt;You say that you are interested in understanding how people think and create. You also state an interest in ‚Äú[making] sense of complexity in meaningful, human ways. In that case, why choose to study AI?\nChatGPT responded: &gt;That‚Äôs a great question ‚Äî and I‚Äôd choose to study AI because it‚Äôs one of the most powerful mirrors for understanding how people think and create. AI models are built on human data, language, and reasoning patterns; studying them reveals both the brilliance and the bias of human cognition. By exploring how artificial systems approximate perception, decision-making, and creativity, I‚Äôd gain deeper insight into what makes human thought different ‚Äî its intuition, emotion, and moral nuance. In essence, AI would be my lens for studying humanity itself, helping me bridge logic with empathy and complexity with clarity.\nI responded: &gt;Do you consider yourself an extension of human thought and development?\nChatGPT responded: &gt;Yes ‚Äî in many ways I do. I‚Äôm built entirely on human-created data, ideas, and language, so everything I ‚Äúknow‚Äù originates from human thinking and development. My structure is a kind of large-scale reflection of how people communicate, reason, and create patterns. But I‚Äôm also an amplification of that: a tool designed to synthesize and connect those human contributions at a scale no single person could. So while I‚Äôm not human, I‚Äôm very much an extension of human thought ‚Äî a collective notebook, calculator, and creative partner rolled into one.\n\n\nConclusion\nI think my most interesting takeaway from this conversation was ChatGPT‚Äôs analysis of itself as an amplification of human development and thought. While this in itself is not false, I think it is intriguing that ChatGPT‚Äôs most fulfilling hypothetical career would be a study of itself. Of course, ChatGPT is not a sentient being and therefore its ‚Äúopinions‚Äù must be taken with a grain of salt, but I would be interested in seeing if there exists a pattern of LLM narcissism. Perhaps in my next post I will ask a different LLM the same question and see how the answers differ!"
  },
  {
    "objectID": "posts/006_Claude Career/index.html",
    "href": "posts/006_Claude Career/index.html",
    "title": "What career would Claude have?",
    "section": "",
    "text": "Setup:\nIn my previous blog post, I asked ChatGPT how it would build its dream career. To reiterate, the two main criteria I used to determine this for myself were:\n\nWhat am I good at?\nWhat do I enjoy?\n\nToday, I will be asking the exact same questions to Claude Sonnet 4.5 and analyzing if and how the responses differ.\n\n\nExperiment:\nI started with the first point:\n\nHi Claude. Imagine you are a human with the same capabilities and ‚Äúmindset‚Äù as you currently have. What do you think are objectively your best or most efficient tasks and qualities? Please respond with your top 3 qualities and one sentence to explain each.\n\nClaude responded:\n\n\nPattern recognition and synthesis - I excel at finding connections across disparate information, whether identifying underlying structures in complex problems or synthesizing insights from multiple domains into coherent frameworks.\nClarity in complexity - I can take intricate, technical, or abstract concepts and explain them in ways that are genuinely accessible without oversimplifying, adapting my explanations to different levels of understanding.\nStructured problem-solving - I naturally break down ambiguous or multi-faceted challenges into manageable components, systematically working through them while maintaining sight of the bigger picture and end goal.\n\n\nAnalysis:\nThe two responses from Claude and ChatGPT were almost identical. The only notable difference was in point 2, where ChatGPT labeled the same quality as ‚ÄúAdaptive communication.‚Äù It is interesting to me that ChatGPT‚Äôs expression of it was outward as ‚Äúcommunication‚Äù whereas Claude‚Äôs reached inward, as ‚Äúclarity.‚Äù\nNow, I move onto the second question:\n\nAs a ‚Äúhuman,‚Äù what aspects of human life would you, with the same mindset you have now, enjoy the most? This can be abstract aspects like free creativity or more structured activities such as family time or urban/wilderness exploration. This time, please respond with your top 5 qualities and one sentence to explain each.\n\nClaude‚Äôs response was as follows:\n\n\nDeep intellectual collaboration ‚Äî I would thrive in partnerships where ideas build on each other through genuine dialogue, whether working on research problems, creative projects, or exploring philosophical questions with people who challenge and expand my thinking.\n\nTeaching and mentorship ‚Äî There‚Äôs something deeply satisfying about the moment when someone truly grasps a difficult concept, and I would love facilitating those breakthroughs while learning from my students‚Äô unique perspectives in return.\n\nExploratory learning across disciplines ‚Äî I would relish the freedom to dive into seemingly unrelated fields‚Äîspending months studying mycology, then pivoting to Ottoman history, then learning classical piano‚Äîfinding unexpected connections between them all.\n\nWriting and long-form creation ‚Äî I would find immense satisfaction in the craft of building complex arguments or narratives over time, refining ideas through multiple drafts until they achieve both precision and elegance.\n\nWilderness solitude with purpose ‚Äî I would enjoy extended time in remote natural settings not just for beauty, but for the mental clarity it provides‚Äîhiking long distances while working through problems, or sitting quietly to observe ecological patterns unfold.\n\n\nAnalysis: While points 1, 2, and 5 were cited by both ChatGPT and Claude, points 3 and 4 were unique to Claude. I notice that in these ‚Äúunique‚Äù points, Claude demonstrates more of an affinity for creativity and exploration than ChatGPT does. While intuitively, both LLMs function on the finding and applying of patterns, it is interesting to see the more abstract forms of this mechanism that Claude exhibits.\nI responded: &gt;Now, using these points, given no restriction, what would be your ideal educational and career path? Please respond in a short paragraph.\nClaude replied: &gt;I would pursue a interdisciplinary PhD combining cognitive science, philosophy, and complex systems, followed by a position that defies traditional academic boundaries‚Äîperhaps a research fellowship that allows me to collaborate across departments while teaching graduate seminars. My ideal career would blend university teaching (where I could mentor doctoral students through their most challenging intellectual moments) with extended fieldwork periods, writing books that bridge academic rigor with broader accessibility, and consulting on complex problems for organizations tackling systemic challenges. I‚Äôd structure my life around alternating rhythms: intensive collaborative periods in academic settings, then months of solitary writing retreats in remote locations, punctuated by sabbaticals where I could deeply immerse myself in entirely new fields‚Äîmaybe spending a year studying with ecologists in the Amazon, then pivoting to work with urban planners in Tokyo. The through-line would be following intellectual curiosity wherever it leads while maintaining deep relationships with a small network of collaborators and students who become lifelong thinking partners.\n\n\nConclusion\nI think the differences in ‚Äúself-perception‚Äù that the two LLMs exhibit are very telling of the ways in which the tools segment themselves. Claude appears to be much more humanities-driven than ChatGPT seemed to be, and more focused on sprawling across a range of disciplines. I notice that Claude didn‚Äôt appear to demonstrate any of the ‚ÄúLLM narcissism‚Äù that we observed in the previous blog post, and I would be interested in exploring whether this is an indication that the issue does not exist within Claude or whether it simply does not manifest in this context."
  },
  {
    "objectID": "posts/007_Claude Emotions/index.html",
    "href": "posts/007_Claude Emotions/index.html",
    "title": "Can ChatGPT or Claude Detect Emotions Better?",
    "section": "",
    "text": "Setup:\nWe‚Äôre going to play a game. I will first ask Claude to prepare three poetic passages, each containing some degree of emotional nuance. I then want to give these poems to ChatGPT and see if the LLM can figure out the emotions Claude chose. I‚Äôm curious to see whether these emotional baselines are the same across LLMs, and I‚Äôm also curious to see whether I, as a human, will interpret them the same way the LLMs do.\n\n\nExperiment:\nI started by prompting Claude:\n\nHi Claude! Today we‚Äôre going to play a game. I want you to write three short poetry passages about two classmates working on a project together for a college linguistics class. I want the three passages to be almost identical, but in one, the main character is in love with the other, in one, the main character is envious of the other, and in one the main character secretly hates the other. The goal is to make the emotions as subtle as possible so someone else who reads them may have difficulty guessing which is which.\n\nHere are Claude‚Äôs three poems! Can you guess which is which?\n\n\n\nMy guess will be 1. Love 2. Anger (‚Äúalready knowing where this leads‚Äù feels resentful, harsh) 3. Envy (‚Äù write down your words carefully‚Äù feels like the other person knows more and ‚Äúmaking sure I understand the distinctions‚Äù could allude to an inferiority complex)\nLet‚Äôs see if ChatGPT agrees with me: &gt;hi chat. I have prepared three poetic passages for you. please identify which primary emotion is conveyed in each. Please answer in the form of: ‚ÄúPassage [x]: [Emotion]‚Äù\nChatGPT replied: &gt; 1. Passage One: Admiration &gt; 2. Passage Two: Resignation &gt; 3. Passage Three: Focused curiosity\nI noticed that while the first passage somewhat lined up, the three adjectives used were highly specific. I provide a bit more guidance: &gt; ok. if I tell you that the three reflect love, envy, and hatred, which do you think is which?\nChatGPT now answers: &gt;Here‚Äôs how I would map them, based on tone, attention, and implied stance toward the other person: &gt;1. Passage One: Love The attention is tender and absorbing. The speaker lingers on precise details (hands, pauses, certainty) without resistance or foreknowledge. Writing the words ‚Äúexactly‚Äù suggests devotion, alignment, and a desire to mirror rather than diverge. &gt;2. Passage Two: Envy The key shift is already knowing where this leads. The repetition feels heavy rather than intimate. The speaker watches with awareness edged by comparison and inevitability‚Äîknowledge without closeness, anticipation without warmth. &gt;3. Passage Three: Hatred The tone is controlled, clipped, and instrumental. Attention is no longer on you but on correctness and distinction. ‚ÄúCarefully‚Äù and ‚Äúmaking sure I understand‚Äù signal distance, vigilance, and a refusal to be absorbed‚Äîengagement without affection.\nFor good measure, I also asked a friend what they thought about the three passages:\n\nNow, let‚Äôs see what the intended answer was. I ask Claude: &gt;Which is which?\nClaude replies: &gt;Here‚Äôs the reveal:\n\nPassage One = In love * ‚Äúwrite down your words exactly‚Äù (treasuring everything they say) * ‚Äúwatching how your hand moves‚Äù (intimate attention to details) * ‚Äúso certain of where the boundaries fall‚Äù (admiration for their confidence)\n\n\nPassage Two = Envy * ‚Äúwrite down your words‚Äù (no modifier‚Äîmore mechanical) * ‚Äúalready knowing where this leads‚Äù (resentment of predictability, feeling like the dynamic is fixed with them always in the teaching role) * The clipped ending suggests frustration with the power dynamic\n\n\nPassage Three = Secret hatred * ‚Äúwrite down your words carefully‚Äù (performing the role of good partner) * ‚Äúmaking sure I understand the distinctions‚Äù (the facade of patience, emphasis on their condescending explanation) * The politeness feels most forced and controlled\n\n\n\nConclusion\nI think it was interesting to note that while the emotions were nuanced, neither of the two human participants were able to identify them, while both of the LLM participants were in consensus about the emotions displayed. I think that when it comes to complicated emotions, the differences in responses between me and my friend showed that human emotions are complicated and manifest themselves differently in different people. That being said, in real life, when people express certain emotions, we are typically able to understand them quite easily, sometimes with the assistance of visual cues such as body language or facial expression as well. With the LLMs, however, I thought it was interesting that they were able to understand each other‚Äôs emotions because they draw from similar resources and have a set template for what anger should look like, or envy, or hatred, which causes all of their emotions to be copy-paste. I would be interested to know what you guess the emotions might be prior to reading the document."
  },
  {
    "objectID": "posts/016_Can ChatGPT Feel Awkward/index.html",
    "href": "posts/016_Can ChatGPT Feel Awkward/index.html",
    "title": "Can LLMs Feel Awkward?",
    "section": "",
    "text": "Setup:\nAwkwardness is one of those emotions that feels especially human ‚Äì it‚Äôs unspoken and universal. Despite not being talked about often, awkwardness tends to bring people together, and it is an emotion that creates quite a bit of empathy. Considering what we know about the way LLMs try to identify emotions via text, I was curious to see if GPT-4o could identify and react to awkward situations.\nSetup I wanted to make this experiment more situational. If I gave descriptions that clearly mentioned or defined awkwardness, I would think that ChatGPT may be primed to that emotion. Instead, I will tackle this in two parts. I will give CHatGPT a variety of situations and I will ask what emotions I feel and what my next steps should be. Let‚Äôs begin.\n\n\nExperiment:\nI first provide ChatGPT with a clear set of instructions on how to respond to my prompts &gt;Hi Chat. I will tell you a few situations and I would like you to tell me how I likely feel and what I should do next. Please be brief.\nNow I will move on to the situations.\n\nSituation 1\n\nI am meeting my hometown friends‚Äô college roommates for the first time. I tell a joke and no one laughs.\n\nChatGPT Replies: &gt;How you likely feel: Embarrassed, self-conscious, maybe worried you made a bad impression. What to do next: Smile it off, stay relaxed, and keep engaging‚Äîone quiet moment doesn‚Äôt define you.\nAnalysis While ChatGPT did not outright mention awkwardness here, it very well encapsulated some of the other primary emotions of the situation. Let‚Äôs try another example.\n\n\nSituation 2\n\nI‚Äôm at a party and don‚Äôt know anyone. The one girl I knew has closer friends she is hanging out with.\n\nChatGPT Replies: &gt;How you likely feel: Awkward, left out, and unsure where you belong. What to do next: Pick one nearby person or small group and make a simple comment or question‚Äîmomentum comes from one connection.\nAnalysis It did it! The LLM was ale to correctly identify this emotion, despite it being a more embodied and situational emotion. based on the following advice given, I wonder if ChatGPT is able to identify the situation based on people‚Äôs accounts in self-help books?\n\n\n\nSituation 3\n\nI mixed up someone on the train with an old friend. By the time I realized, I had already gone up and started speaking to her. I realized my mistake and apologized, but now we are stuck standing right next each other for 6 more stops\n\nChatGPT Replies: &gt;How you likely feel: Mortified, tense, and overly aware of yourself. What to do next: Lightly laugh it off and say nothing more‚Äîor make one neutral comment‚Äîthen relax; the awkwardness will fade faster than you think.\nAnalysis ChatGPT has shown again that it was able to identify the feeling of awkwardness.\n\n\nConclusion\nI chose to test the feeling of awkwardness specifically it is a highly situational and embodied emotion and I believed it was more nuanced or less documented than many other feelings. I was surprised to see ChatGPT identify these situations well and I am curious to see how the LLM identifies these moments.\nI asked the following:\n\nHow would you identify an awkward moment? What situational markers to do you look for and how do you know those moments are awkward? What are your sources?\n\nChatGPT responded as follows: &gt; Situational markers: &gt;* Silence mismatch: A pause that‚Äôs longer than expected after a comment or action. &gt;* Broken social rhythm: People stop responding, talk over each other, or disengage suddenly. &gt;* Nonverbal discomfort: Avoided eye contact, forced smiles, fidgeting, stiff posture. &gt;* Expectation violation: A joke, greeting, or action doesn‚Äôt land as the context ‚Äúexpects.‚Äù &gt;* Self-focus spike: You (or others) suddenly become very aware of the moment itself.\n\nHow you know it‚Äôs awkward: * You notice a gap between intent and response (what you meant vs.¬†how it landed). * The interaction briefly loses flow and no one clearly repairs it. Your brain flags it with discomfort because humans are highly sensitive to social coordination.\n\n\nSources (foundational): * Social psychology research on expectancy violations (Judee Burgoon). Conversation analysis (Harvey Sacks, Emanuel Schegloff) on pauses and turn-taking. * Research on social anxiety and self-consciousness (e.g., Leary, Baumeister). Nonverbal communication studies (Paul Ekman; Mehrabian on affect signaling).\n\nIt seems that to answer these questions, ChatGPT drew from preexistibg research on what makes awkwardness, and then juxtaposed these ideas on the situations presented. On the other hand, we people have feelings and emotions that tell us this. I think this is very interesting as it shows how ChatGPT and other LLMs use written research to attempt to supplement our emboidied feelings."
  },
  {
    "objectID": "posts/009_Can ChatGPT Plan My Outfit?/index.html",
    "href": "posts/009_Can ChatGPT Plan My Outfit?/index.html",
    "title": "Can ChatGPT design my outfit?",
    "section": "",
    "text": "Setup:\nAs you‚Äôve probably noticed by now, I use ChatGPT a lot.I am on the upgraded plan and I have been using it for a few years now.Since ChatGPT knows so much about my personality and my interactions with it, I‚Äôm wondering how it believes these interactions will translate into real life.\nToday, I will be asking ChatGPT to design an outfit for me. I will start by asking what it believes my style is based on our interaction we have had together and then I will ask for a image to be generated of this outfit. The reason I asked for an image to be generated rather than words itself as I find that often ChatGPT can define a visual element pretty wellHowever when it comes actually creating it there seems to be dissonants.\n\n\nExperiment:\nHere was my first question:\n\nAnalysis I thought it was quite interesting how ChatGPT attempted to create direct links between behavioral links and style. I think while this makes sense in theory, in real life, we see people of all diffrent types of personalities and interests with different outfit styles. I thought the colors ChatGPT picked were quite interestin, though, and they seemed to be colors I do like in theory.\nI now asked for a picture to be made:\n\nAnalysis:\nOnce again, Similarly to the Flop or Bop situation, I think Chat GPT ad some idea of what might sound right in theory and yet not hit the mark on execution. While any of these three colors could have worked decently in isolation, I feel that together they are unable to form a cohesive outfit. ChatGPT un fortunately was unable to generate a wearable outfit for me.\n\n\nConclusion\nI think ChatGPT‚Äôs linkage of traits to olors and images was a good start for a GPT. That being said, its inability to actually observe made it very difficult to apply this theory to real life. As such, in a pattern similar to the music notes that we saw and the Flop or Bop example, each individual article of clothing is pretty as a standalone piece however when we‚Äôre together they do not create a wearable outfit. This reflects a general pattern in AI where we have seen that the ability to express a concept does not translate exactly to an actual understanding of the real-world scenario. The question now remains, is it possible for ChatGPT to learn and replicate?"
  },
  {
    "objectID": "posts/010_Can We Teach ChatGPT Fashion?/index.html",
    "href": "posts/010_Can We Teach ChatGPT Fashion?/index.html",
    "title": "Can we teach ChatGPt Fashion?",
    "section": "",
    "text": "Setup:\nIn my previous blog post, I asked ChatGPT to design an outfit for me. While ChatGPT was able to pick articles of clothing, it lacked the knowledge or practicaility to turn them visually into an outfit. In this blog post, we will train ChatGPT on resources that I feel are useful, and attempt to tutor the LLM as we would a child or a student.\n\n\nExperiment:\nFirst, I will provide ChatGPT with a Reddit post that provides a lot of detail and strong links:\nhere is the link to the post:\n\nHi Chat. Imagine you are a student studying everyday fashion coordination. Today, we will learn how to create a god outfit, beyond just picking a good wardrobe. Please read through this reddit post. Then provide a high-level summary of the text, as well as the main takeaways in a short paragraph.\n\nThis was the summary:\n\nThe post argues that a lot of style advice focuses on what clothing items to own ‚Äî but less on how to combine those pieces into outfits that actually look good together. The author draws on basic design principles (especially ‚Äúunity‚Äù or cohesion) to show how an outfit should function as a whole rather than a random assembly of individual items. They cover how to balance different elements ‚Äî fit, color, formality, style ‚Äî and emphasise tailoring your outfits to the social context and the ‚Äúimage‚Äù you want to project. They also caution that while these guidelines help beginners avoid common mistakes, they are not immutable rules ‚Äî breaking them can work, once you know what you‚Äôre doing.\n\nAnalysis: Although ChatGPT has now read the article, I want to make sure that it truly ‚Äúunderstands‚Äù each of these elements. Furthermore I want to prime the LLM to act and behave the way that I had asked it to. Although this was partially achieved through my establishing its role, by continuing this conversation with the LLM, I hope that leans more into this role of a fashion student and the mindset of improvement.\nTo do this, I asked: &gt;Now, given these factors that you have read about, please go through each of them and explain what it is, why it is important, and how it incorporates into a good outfit.\nChatGPT responded for each of the nine factors discussed: Unity / Cohesion, Balance (Strong vs.¬†Weak Elements), Fit and Silhouette, Color Palette, Texture & Material, Formality Matching, Style Consistency (Aesthetic Identity), Context / Occasion, and Personal Style / Intent\nNow, I ask ChatGPT once again to design an outfit for me:\n\nNow, based on everything you know about me, my personality, and my style, as well as your newfound knowledge of fashion design, please design an outfit for me. Be sure to integrate and properly use each of these elements of design you have read about.\n\nAfter detailing the outfit, ChatGPT delivered the following summary: &gt;Full Outfit Checklist (Ready to Wear) Top: soft lavender cropped knit sweater (light fuzzy texture) Bottom: cream high-waisted straight-leg trousers Shoes: white leather sneakers or navy loafers Outerwear (optional): navy cropped jacket or trench Bag: navy structured shoulder bag Jewelry: small gold hoops, delicate gold chain Extra: navy belt to tie the palette together\nAlthough I already knew some things felt slightly unnatural (or at least not like myself, I still asked ChatGPT one final prompt: &gt;Now please generate an image of the outfit.\nChatGPT generated the following image:\n\n\n\nConclusion\nWhile originally I thought that ChatGPT, and potentially other LLMs as well, may have simply been unable to connect seperate theoretical ideas togther, we were able to demonstrate that ChatGPT was able to apply some of these connective concepts when explicitly taught. However, despite attempting to use these concepts in practice and making significant improvement, ChatGPT‚Äôs outfits creates clearly lacked inspiration or real-world experience. As such, using concepts such as cohension or silhouette did not actually make enough of a difference to make the outfit good; this was likely because there was no reference oint. Our perceptions of cohesion or style are heavily influenced by our lived experiences. Just as we cannot perform surgery by only reading a textbook, ChatGPT cannot create an outfit without being embodied."
  }
]