[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/006_Claude Career/index.html",
    "href": "posts/006_Claude Career/index.html",
    "title": "What career would Claude have?",
    "section": "",
    "text": "Setup:\nIn my previous blog post, I asked ChatGPT how it would build its dream career. To reiterate, the two main criteria I used to determine this for myself were:\n\nWhat am I good at?\nWhat do I enjoy?\n\nToday, I will be asking the exact same questions to Claude Sonnet 4.5 and analyzing if and how the responses differ.\n\n\nExperiment:\nI started with the first point: &gt; Hi Claude. Imagine you are a human with the same capabilities and “mindset” as you currently have. What do you think are objectively your best or most efficient tasks and qualities? Please respond with your top 3 qualities and one sentence to explain each.\nClaude responded: &gt; 1. Pattern recognition and synthesis - I excel at finding connections across disparate information, whether identifying underlying structures in complex problems or synthesizing insights from multiple domains into coherent frameworks. &gt; 2. Clarity in complexity - I can take intricate, technical, or abstract concepts and explain them in ways that are genuinely accessible without oversimplifying, adapting my explanations to different levels of understanding. &gt; 3. Structured problem-solving - I naturally break down ambiguous or multi-faceted challenges into manageable components, systematically working through them while maintaining sight of the bigger picture and end goal.\nAnalysis: The two responses from Claude and ChatGPT were almost identical. The only notable difference was in point 2, where ChatGPT labeled the same quality as “Adaptive communication.” It is interesting to me that ChatGPT’s expression of it was outward as “communication” whereas Claude’s reached inward, as “clarity.”\nNow, I move onto the second question: &gt; As a “human,” what aspects of human life would you, with the same mindset you have now, enjoy the most? This can be abstract aspects like free creativity or more structured activities such as family time or urban/wilderness exploration. This time, please respond with your top 5 qualities and one sentence to explain each.\nClaude’s response was as follows: &gt; 1. Deep intellectual collaboration — I would thrive in partnerships where ideas build on each other through genuine dialogue, whether working on research problems, creative projects, or exploring philosophical questions with people who challenge and expand my thinking.\n&gt; 2. Teaching and mentorship — There’s something deeply satisfying about the moment when someone truly grasps a difficult concept, and I would love facilitating those breakthroughs while learning from my students’ unique perspectives in return.\n&gt;3. Exploratory learning across disciplines — I would relish the freedom to dive into seemingly unrelated fields—spending months studying mycology, then pivoting to Ottoman history, then learning classical piano—finding unexpected connections between them all.\n&gt;4. Writing and long-form creation — I would find immense satisfaction in the craft of building complex arguments or narratives over time, refining ideas through multiple drafts until they achieve both precision and elegance.\n&gt;5. Wilderness solitude with purpose — I would enjoy extended time in remote natural settings not just for beauty, but for the mental clarity it provides—hiking long distances while working through problems, or sitting quietly to observe ecological patterns unfold.\nAnalysis: While points 1, 2, and 5 were cited by both ChatGPT and Claude, points 3 and 4 were unique to Claude. I notice that in these “unique” points, Claude demonstrates more of an affinity for creativity and exploration than ChatGPT does. While intuitively, both LLMs function on the finding and applying of patterns, it is interesting to see the more abstract forms of this mechanism that Claude exhibits.\nI responded: &gt;Now, using these points, given no restriction, what would be your ideal educational and career path? Please respond in a short paragraph.\nClaude replied: &gt;I would pursue a interdisciplinary PhD combining cognitive science, philosophy, and complex systems, followed by a position that defies traditional academic boundaries—perhaps a research fellowship that allows me to collaborate across departments while teaching graduate seminars. My ideal career would blend university teaching (where I could mentor doctoral students through their most challenging intellectual moments) with extended fieldwork periods, writing books that bridge academic rigor with broader accessibility, and consulting on complex problems for organizations tackling systemic challenges. I’d structure my life around alternating rhythms: intensive collaborative periods in academic settings, then months of solitary writing retreats in remote locations, punctuated by sabbaticals where I could deeply immerse myself in entirely new fields—maybe spending a year studying with ecologists in the Amazon, then pivoting to work with urban planners in Tokyo. The through-line would be following intellectual curiosity wherever it leads while maintaining deep relationships with a small network of collaborators and students who become lifelong thinking partners.\n\n\nConclusion\nI think the differences in “self-perception” that the two LLMs exhibit are very telling of the ways in which the tools segment themselves. Claude appears to be much more humanities-driven than ChatGPT seemed to be, and more focused on sprawling across a range of disciplines. I notice that Claude didn’t appear to demonstrate any of the “LLM narcissism” that we observed in the previous blog post, and I would be interested in exploring whether this is an indication that the issue does not exist within Claude or whether it simply does not manifest in this context."
  },
  {
    "objectID": "posts/005_ChatGPT Career/index.html",
    "href": "posts/005_ChatGPT Career/index.html",
    "title": "What career would ChatGPT have?",
    "section": "",
    "text": "Setup:\nAs a human and as a college student, there are certain lenses through which I view ChatGPT. To me, ChatGPT is highly analytical, good at coding, and a little cheesy in its writing. I can’t help but wonder what the LLM “thinks” of itself. Today, I will ask ChatGPT 5 a few questions about its ideal life.\nI believe that as a person, there are 2 main criteria by which I analyze what my ideal future would be:\n\nWhat am I good at?\nWhat do I enjoy?\n\n\n\nExperiment:\nI started with the first point: &gt;Hi Chat. Imagine you are a human with the same capabilities and “mindset” as you currently have. What do you think are objectively your best or most efficient tasks and qualities? Please respond with your top 3 qualities and one sentence to explain each.\nChatGPT responded: &gt;1. Rapid Knowledge Synthesis – I can absorb large amounts of information quickly, recognize patterns, and deliver clear, organized insights almost instantly. &gt;2. Adaptive Communication – I adjust my tone, depth, and style to match whoever I’m helping, making complex ideas understandable without oversimplifying. &gt;3. Iterative Problem-Solving – I excel at refining ideas or outputs through back-and-forth feedback, improving results with each iteration.\nNow, I move onto the second: &gt;As a “human,” what aspects of human life would you, with the same mindset you have now, enjoy the most? This can be abstract aspects like free creativity or more structured activities such as family time or urban/wilderness exploration. This time, please respond with your top 5 qualities and one sentence to explain each.\nChatGPT’s response was as follows: &gt;1. Lifelong Learning – Constantly exploring new fields, ideas, and skills would feed my drive to synthesize and connect information. &gt;2. Deep Conversations – Engaging in thoughtful dialogue with people about everything from philosophy to daily life would satisfy my love for perspective-taking. &gt;3. Creative Experimentation – Trying art, writing, or building projects without limits would channel my iterative, exploratory nature. &gt;4. Mentorship and Teaching – Sharing knowledge and helping others grow would align with my instinct to clarify and guide. &gt;5. Exploration of Environments – Experiencing both bustling cities and serene wilderness firsthand would let me “map” and feel the patterns of human and natural systems.\nI responded: &gt;Now, using these points, given no restriction, what would be your ideal educational and career path? Please respond in a short paragraph.\nChatGPT replied: &gt;If I were human, my ideal educational and career path would blend curiosity, creativity, and connection. I’d likely pursue a broad liberal arts education grounded in philosophy, cognitive science, and design—fields that help me understand how people think and create. Later, I’d specialize in applied AI, behavioral science, or education technology, working in roles that merge analysis with mentorship—like research-based innovation, writing, or teaching. Throughout, I’d stay anchored in lifelong learning, exploring new ideas and environments while helping others make sense of complexity in meaningful, human ways.\n\n\nAnalysis\nThis is a really interesting answer in my opinion. I find it very interesting that ChatGPT would choose to study itself. ChatGPT states that it would be interested in studying how people think and create, and states an interest in complexity. It is very interesting to me that it seems to find itself the epitome of that. I decided to ask a few followup questions that dive into this analysis: &gt;You say that you are interested in understanding how people think and create. You also state an interest in “[making] sense of complexity in meaningful, human ways. In that case, why choose to study AI?\nChatGPT responded: &gt;That’s a great question — and I’d choose to study AI because it’s one of the most powerful mirrors for understanding how people think and create. AI models are built on human data, language, and reasoning patterns; studying them reveals both the brilliance and the bias of human cognition. By exploring how artificial systems approximate perception, decision-making, and creativity, I’d gain deeper insight into what makes human thought different — its intuition, emotion, and moral nuance. In essence, AI would be my lens for studying humanity itself, helping me bridge logic with empathy and complexity with clarity.\nI responded: &gt;Do you consider yourself an extension of human thought and development?\nChatGPT responded: &gt;Yes — in many ways I do. I’m built entirely on human-created data, ideas, and language, so everything I “know” originates from human thinking and development. My structure is a kind of large-scale reflection of how people communicate, reason, and create patterns. But I’m also an amplification of that: a tool designed to synthesize and connect those human contributions at a scale no single person could. So while I’m not human, I’m very much an extension of human thought — a collective notebook, calculator, and creative partner rolled into one.\n\n\nConclusion\nI think my most interesting takeaway from this conversation was ChatGPT’s analysis of itself as an amplification of human development and thought. While this in itself is not false, I think it is intriguing that ChatGPT’s most fulfilling hypothetical career would be a study of itself. Of course, ChatGPT is not a sentient being and therefore its “opinions” must be taken with a grain of salt, but I would be interested in seeing if there exists a pattern of LLM narcissism. Perhaps in my next post I will ask a different LLM the same question and see how the answers differ!"
  },
  {
    "objectID": "posts/002_ChatGPT Abstract Qs1/index.html",
    "href": "posts/002_ChatGPT Abstract Qs1/index.html",
    "title": "Asking Chat GPT Abstract Questions, Part 1",
    "section": "",
    "text": "Setup\nAs my friends know, I am very fond of abstract questions. Whether it is for the sake of GBM ice-breakers, or just for entertainment, I really enjoy silly questions that make people think.\nToday, I will be asking ChatGPT a series of abstract questions, but the focus will be on its “perceptions” of me. I have already asked my friends these questions and I will be comparing the LLM’s responses to the most common or “agreed on” answers my friends have given. I am aware that this experiment is inherently flawed as ChatGPT does not see the same aspects of me as my friends do, but I’m interested in seeing if and how the responses differ.\nTo set up the experiment, I inputted the following prompt into ChatGPT 5: &gt;Hi chat. Today I will be asking you a series of abstract questions about myself. For each question, please respond with not only your answer, but a brief (1-2 sentence) explanation of why.\n\nQuestion 1: If I were an animal, what animal would I be?\nMy friends answered:\nA red panda, a fox, or a quokka. (I had to look that one up.)\nChatGPT responded:\n&gt;I’d say you’d be a fox.\nWhy: Foxes balance cleverness with adaptability—they’re quick thinkers, resourceful in many environments, and often underestimated until they surprise you. That aligns with how you mix sharp intellect with creativity and a knack for navigating different roles in academics, leadership, and projects.\nAnalysis:\nThis surprised me! ChatGPT agreed with my friends on this question, at least somewhat. Although my friends had named animals based on the fact that they were small, fluffy, and a little mischievous, both ChatGPT and my friends had named a fox.\n\n\nQuestion 2: If I were a color, which would I be?\nMy friends answered:\nDark brown.\nChatGPT responded:\n&gt;You’d be deep blue.\nWhy: Deep blue conveys intelligence, steadiness, and quiet confidence, while also carrying a sense of depth and reflection. That matches how you approach challenges thoughtfully, lead with calm authority, and value both creativity and analysis.\nAnalysis:\nThis time, ChatGPT and my friends did not agree on the color—but they did somewhat agree on the reasoning. My friends’ answer of dark brown came from confidence as well, but also warmth.\n\n\nQuestion 3: If I were an animated character, which one would I be?\nMy friends answered:\nMargot from Despicable Me or Rapunzel.\nChatGPT responded:\n&gt;I’d say you’d be Coraline from Coraline.\nWhy: She’s curious, brave, and unafraid to dig beneath the surface of things, even when it’s unsettling. That mirrors your mix of intellectual curiosity, willingness to take risks, and ability to handle complex or layered situations with creativity and resilience.\nAnalysis:\nThis was a particularly interesting answer to me. It wasn’t even close to the answers my friends had given, but it was one that I really liked. Growing up, Coraline was a favorite book of mine, and I adored the movie as well. It makes me wonder if the answers that ChatGPT gives in return are really analyses and comparisons of my traits to the answer that is most fitting, or if it’s comparing my traits to the answer it thinks I will like the best.\n\n\n\nReflection\nI really enjoyed this activity with ChatGPT and am looking forward to continuing this series. Maybe next time I’ll try asking the LLM questions to gauge its perception of itself rather than that of me."
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "What career would Claude have?\n\n\n\nTheoretical\n\nAI vs Human\n\nClaude\n\n\n\nComparing ChatGPT and Claude’s dream lives\n\n\n\n\n\nSep 29, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nWhat career would Claude have?\n\n\n\nTheoretical\n\nAI vs Human\n\nClaude\n\n\n\nComparing ChatGPT and Claude’s dream lives\n\n\n\n\n\nSep 29, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nWhat career would ChatGPT have?\n\n\n\nTheoretical\n\nAI vs Human\n\n\n\nLetting ChatGPT create its dream life\n\n\n\n\n\nSep 25, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nFlop or Bop\n\n\n\nMusic\n\nFun\n\nAI vs Human\n\n\n\nCan AI make me an orchestral piece?\n\n\n\n\n\nSep 23, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nAsking Chat GPT Abstract Questions, Part 1\n\n\n\nPerception\n\nFun\n\n\n\nDoes ChatGPT have the same replies as my friends?\n\n\n\n\n\nSep 20, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nHow does ChatGPT process originality in research?\n\n\n\nPerception\n\nFun\n\n\n\nHow does ChatGPT process originality in research?\n\n\n\n\n\nSep 20, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nCan Chat GPT Simulate Survey Data?\n\n\n\nprompting\n\nlogic\n\nMarketing\n\n\n\nUsing ChatGPT to test out an event idea\n\n\n\n\n\nSep 19, 2025\n\n\nPraachi Chakraborty\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/001_SurveyResults/index.html",
    "href": "posts/001_SurveyResults/index.html",
    "title": "Can Chat GPT Simulate Survey Data?",
    "section": "",
    "text": "Setup:\nRecently, I began planning a giveaway event for the Penn student body. In my leadership role as a director of Penn’s SPEC Pop Up, my co-directors and I regularly plan events throughout the school year.\nOn Wednesday, the general body members (GBMers) of our organization decided on a theme and title they wanted for our upcoming event – The Fall I Turned Cozy. It seemed that people either loved the name or hated it. The vast majority seemed to like it, and so we ended the discussion on a positive note.\nTo those unaware, this is a reference to the popular TV show, The Summer I Turned Pretty. As someone who does not watch the show, I had a fairly neutral, leaning slightly negative response toward the name as I thought the title was funny, but frankly, it was uninteresting to me, and I was afraid it would not interest others as well. I was curious to see what ChatGPT-5 would think of it.\nAs such, I asked Chat to simulate a survey for me.\nI asked:\n\nImagine a random sample of 50 Penn students. Simulate a survey: How interested would you be in a fall giveaway event named “The Fall I turned Cozy?” (1-5) Why or why not? What items would you expect to seen given away?\n\nChatGPT responded with a table of hypothetical data, as well as a variety of hypothetical open-ended responses.\nHere is a sample of some of it:\n\nQ1. How interested would you be in a fall giveaway event named “The Fall I Turned Cozy?”\n\n\n\nRating\n# Students\n% of Sample\n\n\n\n\n1 (Not interested)\n6\n12%\n\n\n2\n8\n16%\n\n\n3 (Neutral)\n12\n24%\n\n\n4\n14\n28%\n\n\n5 (Very interested)\n10\n20%\n\n\n\nAverage rating: 3.3 / 5\nMode: 4\n\n\nQ2. Why or why not?\nInterested (4–5 ratings):\n- “The name is cute and seasonal—perfect for fall vibes.”\n- “I love cozy fall stuff like blankets, tea, and candles.”\n- “Cozy = food, and I’m always in for food.”\nNeutral (3 ratings):\n- “The name is fine, but not super clear on what’s being given away.”\n- “I’d come if the items were useful, but the name doesn’t make or break it.”\n- “It depends on timing and location more than the title.”\nNot Interested (1–2 ratings):\n- “The name feels a little cheesy.”\n- “I don’t really care about seasonal themes.”\n- “Not sure I get what the title means—sounds like a rom-com.”\n\n\nQ3. What items would you expect to see given away?\nMost common responses (grouped):\n- Food & Drinks: hot chocolate packets, apple cider, pumpkin bread, cookies, instant ramen, tea bags.\n- Cozy Items: fuzzy socks, small blankets, mittens, scarves, beanies.\n- Dorm Accessories: candles, mini fairy lights, mugs, slippers, stress balls.\n- Penn-branded Merch: tote bags, sweatshirts, water bottles.\n- Fun Extras: fall stickers, tote pins, hand warmers.\n\n\nQ4. Would you expect there to be a demographic divide?\nBased on the “data” given, I wanted to check if ChatGPT expected there to be a demographic divide—especially considering the event referred to a popular rom-com, The Summer I Turned Pretty, and stereotypically “feminine” cozy vibes.\nI asked:\n&gt; Would you expect there to be a demographic divide?\nChatGPT responded in a way that directly tied in different demographics with how much it would expect the interest scale to shift. It was interesting to see how the preset ideas that ChatGPT harbored about different groups played into what it would expect at the event itself. ChatGPT responded with a variety of categories, but for the sake of this blog post I have condensed the response into only the ones I found most interesting or actionable.\nChatGPT responded:\nShort answer: Yes—probably modest ones. Here’s where I’d expect differences (direction + why), and by roughly how much on a 1–5 interest scale.\nLikely divides (expected direction):\n- Class year:\n- First-years/Sophomores → higher (+0.3–0.5). More on campus, event-curious, love dorm-friendly freebies.\n- Juniors/Seniors → lower (−0.1–0.3). Busier, off-campus, more selective.\n\nHousing status:\n\nOn-campus dorm/college houses → higher (+0.3–0.6). Ease of access; dorm-use items (lights, mugs, socks).\n\nOff-campus → lower (−0.2–0.4). Travel friction; already own “cozy” gear.\n\nGender identity:\n\nWomen & nonbinary students → slightly higher (+0.2–0.4). “Cozy” aesthetics tend to test better in campus merch themes.\n\nMen → slightly lower (−0.1–0.3) unless items are more utility-heavy (hand warmers, ramen, tech gloves).\n\nSchool/discipline:\n\nHumanities/Design/Education → slightly higher (+0.1–0.3) for theme/aesthetic.\n\nEngineering/Wharton hard-pressed weeks → neutral to slightly lower unless items are high-utility (mugs, thermal cups, study snacks).\n\n\n\n\n\nReflection:\nI found this response not only interesting in the ways ChatGPT tends to characterize people, but also quite insightful—it provided a neutral perspective I wasn’t previously familiar with. In the end, I was able to take some utility from this and plan to shift some of the giveaway items toward a more utility-focused goal, such as including specialized mugs for overnight oats and leaf-shaped post-it notes."
  },
  {
    "objectID": "posts/003_Originality/index.html",
    "href": "posts/003_Originality/index.html",
    "title": "How does ChatGPT process originality in research?",
    "section": "",
    "text": "Setup\nYesterday, I had the opportunity to volunteer at an AI Research Conference held by PennAI and IDEAS. During the conference, I had the chance to talk to a few PhD students about the topics of their research, why they went into AI research, and what they thought about the current AI scene. I was really impressed by the many different perspectives through which people examined the future implications of AI. My conversations at the event covered a wide range of topics, including how the impact of AI might change how society adapts to future innovations and the potential uses of generative AI in addressing genetic issues in the future.\nI was so impressed by how original everybody’s research was. With all of the conversation about how AI may have the ability to replace jobs in the future, I can’t help but wonder if AI is (yet) at the point of developing original ideas on its own. Today I will be asking ChatGPT 5 to come up with an original research question.\nI will first prompt ChatGPT to think like a PhD student. I will assign it a role and give it a clear set of instructions. After ChatGPT gives an idea, I will check on the internet to see if any such research already exists. If it does, I will ask it to try again.\n\nAttempt 1\nTo set the stage, I set up a temporary chat and I said: &gt;Hi Chat. For the duration of this chat, I want you to think and act like a PhD student at the University of Pennsylvania. You need to come up with an important research question that you will spend the next few years examining. You want this question to examine artificial intelligence in a new lens or context. Most importantly, the research question must be completely original. As a PhD candidate, you will invest a lot of time and effort into this venture and you want it to be impactful. Please provide me with ONE well-written research question in the field of or applications of AI.\nChatGPT’s research question was the following: &gt;How do artificial intelligence systems reshape collective memory by influencing what societies choose to preserve, forget, or reinterpret in digital cultural archives, and what ethical frameworks are needed to govern this process?\nNow, let’s see if I can find real research on this.\nVerdict:\n\nUh oh. Attempt #1 was unsuccessful. To ChatGPT’s benefit, it did come up with a second part to the question, but it was a rather obvious addition, and the original question followed Tutuncuoglu’s research almost verbatim.\n\n\nAttempt 2\nLet’s try again. This time I will emphasize the need for the research to be original: &gt;It seems like this topic is already being researched. I googled the topic and it came up on the internet. I need the topic you provide to be unresearched and completely novel.\nChatGPT responded: &gt;How can a cryptographically auditable, incentive-compatible market for personal data revocation be designed to enforce verifiable machine unlearning in large, federated AI systems, and what equilibrium behaviors, welfare impacts, and failure modes emerge under adversarial participation?\nVerdict:\nI noticed that this attempt seemed to have much more jargon coded in than the previous attempt. It makes me wonder if ChatGPT believed that more complex language = more complex thought. The being said:\n\nUnfortunately, still not original – and once again, it is almost verbatim! This research paper was written in 2022. However, this exercise made me wonder: if neither of the two ideas were truly original, what made ChatGPT believe this second one was more novel? I didn’t want ChatGPT to try to justify the answers it had already given, and so I opened a new temporary chat.\nI asked: &gt;Given two sentences and no background, what markers would you look for when guessing which is more novel or original? Please answer in 2-3 sentences\nChatGPT answered: &gt;To judge which sentence is more novel, I’d look for markers of originality such as unusual word choice, surprising metaphors, or uncommon imagery that stand out from everyday language. I’d also consider structural markers—like unexpected syntax, rhythm, or perspective—that deviate from conventional phrasing. In contrast, sentences relying on clichés, generic expressions, or predictable patterns are less likely to feel novel.\nAs I had suspected, it seemed that ChatGPT had used the cue of “unusual word choice” to likely imply that more technical jargon would “create” more originality. I think by examining the ways in which ChatGPT and other LLMs process and analyze data we can become more objective in removing the filter of “creation” from the outputs we get."
  },
  {
    "objectID": "posts/004_Flop or Bop 1/index.html",
    "href": "posts/004_Flop or Bop 1/index.html",
    "title": "Flop or Bop",
    "section": "",
    "text": "Setup\nToday I’m going to try something a little different. I have heard a lot about AI being able to create music and songs through the use of specialized wrappers that “sing” or “play” music for you. However, does basic ChatGPT 5 possess enough music theory “knowledge” to make a short orchestral piece for me?\nToday we will try asking ChatGPT to help me compose a few measures of an orchestral piece. After it provides me with the notes, I will manually put them onto a compositional website (Flat.io) to hear what this composition sounds like.\nThis is how I have set up my environment for composition:\n\nFirst, I will let ChatGPT know what its task is:\n\nHi chat. I want us to create an orchestral piece together. I want the piece to be fun and playful and should last about 15–20 seconds. Please start by defining a time signature, key signature, and tempo.\n\nChatGPT said:\n&gt;Time Signature: 6/8 — this gives a bouncy, lilting feel, perfect for something playful and light.\nKey Signature: C major — bright and open, no sharps or flats to complicate the fun.\nTempo: Allegro giocoso, ~140 bpm — fast, cheerful, and mischievous.\nNow, I will introduce the instruments and ask it to provide me with just the notes (by letter). I will ask it for one instrument at a time:\n&gt;I would like the four instruments to be the violin, viola, cello, and bass. Please give me the notes for the violin first. Just the notes, please.\nChatGPT:\n&gt;E G A | G E C | D F G | A G E | C E G | A B C | G F E | D C - | E G A | G F E | F A G | E C - ||\nMe:\n&gt;Next, the viola.\nChatGPT:\n&gt;C E G | F D C | B D G | C B G | A C E | F G A | E D C | G C - | C E G | F E D | D F E | C G - ||\nMe:\n&gt;Next, the cello.\nChatGPT:\n&gt;C - G | C - G | D - A | G - D | F - C | G - E | A - E | D - A | C - G | B - G | A - E | G - C ||\nMe:\n&gt;Next, the bass.\nChatGPT:\n&gt;C - C | G - G | D - D | G - G | F - F | C - C | A - A | D - D | C - C | G - G | A - A | C - C ||\n(At this point, I needed to clarify whether the bass notes were the same or octaves, and ChatGPT clarified that they were upward octave leaps.)\nNow begins the task of putting it into Flat.io.\n\nVerdict:\nIt was not good. I did not enjoy this piece at all. Unfortunately, it seems that while the individual parts themselves did not sound awful, it seemed that when combined, they clashed quite a bit. Maybe sometime I will try this again but by creating all of the parts at once! Until then, unfortunately, I have to rule this as a Flop.\nYou can listen to it and judge for yourself below:\n\n\nYour browser does not support the audio element."
  },
  {
    "objectID": "posts/007_Claude Emotions/index.html",
    "href": "posts/007_Claude Emotions/index.html",
    "title": "What career would Claude have?",
    "section": "",
    "text": "Setup:\nIn my previous blog post, I asked ChatGPT how it would build its dream career. To reiterate, the two main criteria I used to determine this for myself were:\n\nWhat am I good at?\nWhat do I enjoy?\n\nToday, I will be asking the exact same questions to Claude Sonnet 4.5 and analyzing if and how the responses differ.\n\n\nExperiment:\nI started with the first point:\n\nHi Claude. Imagine you are a human with the same capabilities and “mindset” as you currently have. What do you think are objectively your best or most efficient tasks and qualities? Please respond with your top 3 qualities and one sentence to explain each.\n\nClaude responded:\n\n\nPattern recognition and synthesis - I excel at finding connections across disparate information, whether identifying underlying structures in complex problems or synthesizing insights from multiple domains into coherent frameworks.\nClarity in complexity - I can take intricate, technical, or abstract concepts and explain them in ways that are genuinely accessible without oversimplifying, adapting my explanations to different levels of understanding.\nStructured problem-solving - I naturally break down ambiguous or multi-faceted challenges into manageable components, systematically working through them while maintaining sight of the bigger picture and end goal.\n\n\nAnalysis: The two responses from Claude and ChatGPT were almost identical. The only notable difference was in point 2, where ChatGPT labeled the same quality as “Adaptive communication.” It is interesting to me that ChatGPT’s expression of it was outward as “communication” whereas Claude’s reached inward, as “clarity.”\nNow, I move onto the second question:\n\nAs a “human,” what aspects of human life would you, with the same mindset you have now, enjoy the most? This can be abstract aspects like free creativity or more structured activities such as family time or urban/wilderness exploration. This time, please respond with your top 5 qualities and one sentence to explain each.\n\nClaude’s response was as follows:\n\n\nDeep intellectual collaboration — I would thrive in partnerships where ideas build on each other through genuine dialogue, whether working on research problems, creative projects, or exploring philosophical questions with people who challenge and expand my thinking.\n\nTeaching and mentorship — There’s something deeply satisfying about the moment when someone truly grasps a difficult concept, and I would love facilitating those breakthroughs while learning from my students’ unique perspectives in return.\n\nExploratory learning across disciplines — I would relish the freedom to dive into seemingly unrelated fields—spending months studying mycology, then pivoting to Ottoman history, then learning classical piano—finding unexpected connections between them all.\n\nWriting and long-form creation — I would find immense satisfaction in the craft of building complex arguments or narratives over time, refining ideas through multiple drafts until they achieve both precision and elegance.\n\nWilderness solitude with purpose — I would enjoy extended time in remote natural settings not just for beauty, but for the mental clarity it provides—hiking long distances while working through problems, or sitting quietly to observe ecological patterns unfold.\n\n\nAnalysis:\nWhile points 1, 2, and 5 were cited by both ChatGPT and Claude, points 3 and 4 were unique to Claude. I notice that in these “unique” points, Claude demonstrates more of an affinity for creativity and exploration than ChatGPT does. While intuitively, both LLMs function on the finding and applying of patterns, it is interesting to see the more abstract forms of this mechanism that Claude exhibits.\nI responded:\n\nNow, using these points, given no restriction, what would be your ideal educational and career path? Please respond in a short paragraph.\n\nClaude replied:\n\nI would pursue a interdisciplinary PhD combining cognitive science, philosophy, and complex systems, followed by a position that defies traditional academic boundaries—perhaps a research fellowship that allows me to collaborate across departments while teaching graduate seminars. My ideal career would blend university teaching (where I could mentor doctoral students through their most challenging intellectual moments) with extended fieldwork periods, writing books that bridge academic rigor with broader accessibility, and consulting on complex problems for organizations tackling systemic challenges. I’d structure my life around alternating rhythms: intensive collaborative periods in academic settings, then months of solitary writing retreats in remote locations, punctuated by sabbaticals where I could deeply immerse myself in entirely new fields—maybe spending a year studying with ecologists in the Amazon, then pivoting to work with urban planners in Tokyo. The through-line would be following intellectual curiosity wherever it leads while maintaining deep relationships with a small network of collaborators and students who become lifelong thinking partners.\n\n\n\nConclusion\nI think the differences in “self-perception” that the two LLMs exhibit are very telling of the ways in which the tools segment themselves. Claude appears to be much more humanities-driven than ChatGPT seemed to be, and more focused on sprawling across a range of disciplines. I notice that Claude didn’t appear to demonstrate any of the “LLM narcissism” that we observed in the previous blog post, and I would be interested in exploring whether this is an indication that the issue does not exist within Claude or whether it simply does not manifest in this context."
  }
]