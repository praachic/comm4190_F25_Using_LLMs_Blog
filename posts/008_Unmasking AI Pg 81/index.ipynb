{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ceb26b6d-d77d-4a43-8a72-f9758596005e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Design Is Not Destiny\"\n",
    "description: \"Joy Buolamwini on always questioning the gold standard\"\n",
    "author: \"Praachi Chakraborty\"\n",
    "date: \"10/05/25\"\n",
    "categories:\n",
    "  - Unmasking AI\n",
    "  - AI in Life\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6babcfa-5e2d-48b1-a71c-d91845793138",
   "metadata": {},
   "source": [
    "I think it is undeniable that *Unmasking AI* is a book whose implications stick with you long after you close its pages. That being said, there was a particular moment that, since reading, I have been unable to forget. \n",
    "\n",
    "During this passage, Joy Buolamwini is recounting her time researching at MIT. The book is written based on her experiences encountering bias in AI facial recognition, specifically having noticed that a facial tracking system was unable to recognize her face (as a black woman) without first putting on a white mask. \n",
    "\n",
    "To conclude this particular passage, Joy writes:\n",
    "\n",
    "> “I was left with one major lesson: always question the so-called gold standards. Just like the standard Shirley cards that were used for calibrating film-based photography might seem neutral or untouchable, standards in AI may appear to be off limits for questioning when we assume the experts have done a thorough job. This is not always the case, particularly when the experts do not reflect the rest of society. But design is not destiny. I knew I had to change the system.”\n",
    "> ~ Joy Buolamwini, *Unmasking AI,* pg. 81"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f34b0f8-bf73-4911-854c-19e36af998d9",
   "metadata": {},
   "source": [
    "The logic itself, when boiled down, is quite simple: just because something is the norm doesn't mean it is perfect. Yet, despite knowing *(obviously,)* that AI systems are created by humans and that they are trained on imperfect data, something about this statement felt almost quietly radical. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bc256a-ee6b-4483-b373-faf7af4e002d",
   "metadata": {},
   "source": [
    "### Shirley Cards\n",
    "Notably, Buolamwini is not explicitly saying \"set standards are bad\" or even that AI is bad. The analogy Buolamwini uses here is from old film photography. When color film was first being shown on television, camera companies and TV producers used something called \"Shirley Cards\" to add color and exposure to their productions. These cards were originally calibrated and fine-tuned on a white woman. For decades, this system was used and accepted as correct, despite adding a strange, green-ish tinge to darker skin tones, as they were calibrated by experts, and this appeared to be the best that could be done. The main issue here was not that Shirley Cards were malicious. Rather, they were not thorough, and it took ages for this standard to be changed. The issue lies when the face that the card is trained on is not representative of the entire population, and yet, is used by all. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a5ed3-b671-4f81-8247-71fb81ee2b98",
   "metadata": {},
   "source": [
    "### AI's Gold Standard\n",
    "A lot of AI systems end up repeating the same pattern as we found in the Shirley cards. I often see startups and advertising show terms such as a “gold-standard dataset” or “benchmark accuracy” when describing how well their model can run. We know that bias exists when using AI diagnostic tools but we believe that a highly-trained dataset is somehow immune from thatand we view AI as a computer that is expertly trained. Yet even a \"100% accurate tool\" cannot be entirely trusted. Someone picked the data, labeled it, and decided what is right and wrong. In viewing AI as a machine, we forget the human who trained and built it. \n",
    "\n",
    "The point that Buolamwini makes here is that just because a system is expertly made does not mean it is perfectly or neutrally made, and it is easy to get the two confused. Even beyond AI, I think we will find that the more we examine what we take to be a \"gold standard,\" the more we discover that often the concept of what is correct was defined by a team of imperfect humans. In Buolamwini's words, \"design is not destiny\"; the sooner we stop taking standards as sacred, the sooner we can begin to perfect them. "
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
