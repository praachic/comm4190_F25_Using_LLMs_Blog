{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fe7a7e49-233e-4e45-856d-b7a637d615e7",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Who are the Arbiters of Truth?\"\n",
    "description: \"Joy Buolamwini on truth\"\n",
    "author: \"Praachi Chakraborty\"\n",
    "date: \"12/12/25\"\n",
    "categories:\n",
    "  - Theoretical vs Practical\n",
    "  - Training AI\n",
    "  - ChatGPT\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6babcfa-5e2d-48b1-a71c-d91845793138",
   "metadata": {},
   "source": [
    "### Setup:\n",
    "\n",
    "On page 124 of Unmasking AI, Joy Buolamwini says the following, quote:\n",
    ">\"Instead of erasing our fingerprints from the creation of algorithmic systems, exposing them more clearly gives us a better understanding of what can go wrong, for whom, and why. AI reflects both our aspirations and our limitations. Our human limitations provide ample reasons for humility about the capabilities of the AI systems we create. Algorithmic justice necessitates questioning the arbiters of truth, because those with the power to build AI systems do not have a monopoly on truth.”\n",
    "\n",
    "What Joy Buolamwini is saying here is that we often tend to take finished products at face value. However, even the most polished products come from complicated, flawed human beings. Those mistakes then rub off onto the products that people create. Often, when we take teachings at face value, whether it be new technology or even things we learn at school, we close our eyes to the people that came behind the system. Be it big or small, blind trust in these teachings can have long-lasting effects.\n",
    "\n",
    "In third grade, when we learned that different parts of the tongue had different types of taste buds for sweet, sour, and spicy, I took that at face value. In 1493, when Christopher Columbus returned to Spain, I took that at face value. When Christopher Columbus returned to Spain saying that he had sailed to India, people took that at face value. When people told parents that making their babies listen to Mozart makes children smarter, people took that at face value as well. Obviously, all of these teachings have created different levels of impact, but it is only once we began to question the imperfections of those who discovered these “facts” that we began to understand the truth.\n",
    "\n",
    "This is exactly what Buolamwini argues to culminate this chapter. Speaking of detecting AI biases, she talks about the importance of the development of AI’s detection skills. “The deeper we dive into the development of [them],” she says, “the easier it is to see the human touch that shapes AI systems.” Without understanding the people behind the machine, we cannot predict what can go wrong and why. These are necessary questions we need to answer in order to fix imperfect systems built by imperfect people.\n",
    "\n",
    "Buolamwini’s line on “questioning the arbiters of truth” opens up an important conversation. Truth, which by definition, should be objective, is still subject to the opinions and decisions of people in power. Whether it is due to naivety, oversight, or intrinsic bias, there are a variety of reasons why the people in power cannot determine the truth. But without taking that first step of questioning, we can never fix the broken systems."
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
